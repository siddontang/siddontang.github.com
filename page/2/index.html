<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第 2 页 | Siddon&#39;s Blog</title>
  <meta name="author" content="SiddonTang">
  
  <meta name="description" content="My thought for program">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Siddon&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Siddon&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27956076-1']);
  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Siddon&#39;s Blog</a></h1>
  <h2><a href="/">My thought for program</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/Presentations">Presentations</a></li>
    
      <li><a href="/About">About</a></li>
    
      <li><a href="/atom.xml">RSS</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-07-20T11:03:19.000Z"><a href="/2014/07/20/celery-best-practices/">07-20-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/07/20/celery-best-practices/">celery最佳实践</a></h1>
  

    </header>
    <div class="entry">
      
        <p>作为一个Celery使用重度用户，看到<a href="https://denibertovic.com/posts/celery-best-practices/" target="_blank" rel="external">Celery Best Practices</a>这篇文章，不由得菊花一紧。干脆翻译出来，同时也会加入我们项目中celery的实战经验。</p>
<p>通常在使用Django的时候，你可能需要执行一些长时间的后台任务，没准你可能需要使用一些能排序的任务队列，那么Celery将会是一个非常好的选择。</p>
<p>当把Celery作为一个任务队列用于很多项目中后，作者积累了一些最佳实践方式，譬如如何用合适的方式使用Celery，以及一些Celery提供的但是还未充分使用的特性。</p>
<h2 id="1，不要使用数据库作为你的AMQP_Broker">1，不要使用数据库作为你的AMQP Broker</h2>
<p>数据库并不是天生设计成能用于AMQP broker的，在生产环境下，它很有可能在某时候当机（PS，当掉这点我觉得任何系统都不能保证不当吧！！！）。</p>
<p>作者猜想为啥很多人使用数据库作为broker主要是因为他们已经有一个数据库用来给web app提供数据存储了，于是干脆直接拿来使用，设置成Celery的broker是很容易的，并且不需要再安装其他组件（譬如RabbitMQ）。</p>
<p>假设有如下场景：你有4个后端workers去获取并处理放入到数据库里面的任务，这意味着你有4个进程为了获取最新任务，需要频繁地去轮询数据库，没准每个worker同时还有多个自己的并发线程在干这事情。</p>
<p>某一天，你发现因为太多的任务产生，4个worker不够用了，处理任务的速度已经大大落后于生产任务的速度，于是你不停去增加worker的数量。突然，你的数据库因为大量进程轮询任务而变得响应缓慢，磁盘IO一直处于高峰值状态，你的web应用也开始受到影响。这一切，都因为workers在不停地对数据库进行DDOS。</p>
<p>而当你使用一个合适的AMQP（譬如RabbitMQ）的时候，这一切都不会发生，以RabbitMQ为例，首先，它将任务队列放到内存里面，你不需要去访问硬盘。其次，consumers（也就是上面的worker）并不需要频繁地去轮询因为RabbitMQ能将新的任务推送给consumers。当然，如果RabbitMQ真出现问题了，至少也不会影响到你的web应用。</p>
<p>这也就是作者说的不用数据库作为broker的原因，而且很多地方都提供了编译好的RabbitMQ镜像，你都能直接使用，譬如<a href="https://registry.hub.docker.com/search?q=rabbitmq" target="_blank" rel="external">这些</a>。</p>
<p>对于这点，我是深表赞同的。我们系统大量使用Celery处理异步任务，大概平均一天几百万的异步任务，以前我们使用的mysql，然后总会出现任务处理延时太严重的问题，即使增加了worker也不管用。于是我们使用了redis，性能提升了很多。至于为啥使用mysql很慢，我们没去深究，没准也还真出现了DDOS的问题。</p>
<h2 id="2，使用更多的queue（不要只用默认的）">2，使用更多的queue（不要只用默认的）</h2>
<p>Celery非常容易设置，通常它会使用默认的queue用来存放任务（除非你显示指定其他queue）。通常写法如下：</p>
<pre><code>@app.task()
def my_taskA(a, b, c):
    print(&quot;doing something here...&quot;)

@app.task()
def my_taskB(x, y):
    print(&quot;doing something here...&quot;)
</code></pre><p>这两个任务都会在同一个queue里面执行，这样写其实很有吸引力的，因为你只需要使用一个decorator就能实现一个异步任务。作者关心的是taskA和taskB没准是完全两个不同的东西，或者一个可能比另一个更加重要，那么为什么要把它们放到一个篮子里面呢？（鸡蛋都不能放到一个篮子里面，是吧！）没准taskB其实不怎么重要，但是量太多，以至于重要的taskA反而不能快速地被worker进行处理。增加workers也解决不了这个问题，因为taskA和taskB仍然在一个queue里面执行。</p>
<h2 id="3，使用具有优先级的workers">3，使用具有优先级的workers</h2>
<p>为了解决2里面出现的问题，我们需要让taskA在一个队列Q1，而taskB在另一个队列Q2执行。同时指定<strong>x</strong> workers去处理队列Q1的任务，然后使用其它的workers去处理队列Q2的任务。使用这种方式，taskB能够获得足够的workers去处理，同时一些优先级workers也能很好地处理taskA而不需要进行长时间的等待。</p>
<p>首先手动定义queue</p>
<pre><code>CELERY_QUEUES = (
    Queue(&#39;default&#39;, Exchange(&#39;default&#39;), routing_key=&#39;default&#39;),
    Queue(&#39;for_task_A&#39;, Exchange(&#39;for_task_A&#39;), routing_key=&#39;for_task_A&#39;),
    Queue(&#39;for_task_B&#39;, Exchange(&#39;for_task_B&#39;), routing_key=&#39;for_task_B&#39;),
)
</code></pre><p>然后定义routes用来决定不同的任务去哪一个queue</p>
<pre><code>CELERY_ROUTES = {
    &#39;my_taskA&#39;: {&#39;queue&#39;: &#39;for_task_A&#39;, &#39;routing_key&#39;: &#39;for_task_A&#39;},
    &#39;my_taskB&#39;: {&#39;queue&#39;: &#39;for_task_B&#39;, &#39;routing_key&#39;: &#39;for_task_B&#39;},
}
</code></pre><p>最后再为每个task启动不同的workers</p>
<pre><code>celery worker -E -l INFO -n workerA -Q for_task_A
celery worker -E -l INFO -n workerB -Q for_task_B
</code></pre><p>在我们项目中，会涉及到大量文件转换问题，有大量小于1mb的文件转换，同时也有少量将近20mb的文件转换，小文件转换的优先级是最高的，同时不用占用很多时间，但大文件的转换很耗时。如果将转换任务放到一个队列里面，那么很有可能因为出现转换大文件，导致耗时太严重造成小文件转换延时的问题。</p>
<p>所以我们按照文件大小设置了3个优先队列，并且每个队列设置了不同的workers，很好地解决了我们文件转换的问题。</p>
<h2 id="4，使用Celery的错误处理机制">4，使用Celery的错误处理机制</h2>
<p>大多数任务并没有使用错误处理，如果任务失败，那就失败了。在一些情况下这很不错，但是作者见到的多数失败任务都是去调用第三方API然后出现了网络错误，或者资源不可用这些错误，而对于这些错误，最简单的方式就是重试一下，也许就是第三方API临时服务或者网络出现问题，没准马上就好了，那么为什么不试着重试一下呢？</p>
<pre><code>@app.task(bind=True, default_retry_delay=300, max_retries=5)
def my_task_A():
    try:
        print(&quot;doing stuff here...&quot;)
    except SomeNetworkException as e:
        print(&quot;maybe do some clenup here....&quot;)
        self.retry(e)
</code></pre><p>作者喜欢给每一个任务定义一个等待多久重试的时间，以及最大的重试次数。当然还有更详细的参数设置，自己看文档去。</p>
<p>对于错误处理，我们因为使用场景特殊，例如一个文件转换失败，那么无论多少次重试都会失败，所以没有加入重试机制。</p>
<h2 id="5，使用Flower">5，使用Flower</h2>
<p><a href="http://celery.readthedocs.org/en/latest/userguide/monitoring.html#flower-real-time-celery-web-monitor" target="_blank" rel="external">Flower</a>是一个非常强大的工具，用来监控celery的tasks和works。</p>
<p>这玩意我们也没怎么使用，因为多数时候我们都是直接连接redis去查看celery相关情况了。貌似挺傻逼的对不，尤其是celery在redis里面存放的数据并不能方便的取出来。</p>
<h2 id="6，没事别太关注任务退出状态">6，没事别太关注任务退出状态</h2>
<p>一个任务状态就是该任务结束的时候成功还是失败信息，没准在一些统计场合，这很有用。但我们需要知道，任务退出的状态并不是该任务执行的结果，该任务执行的一些结果因为会对程序有影响，通常会被写入数据库（例如更新一个用户的朋友列表）。</p>
<p>作者见过的多数项目都将任务结束的状态存放到sqlite或者自己的数据库，但是存这些真有必要吗，没准可能影响到你的web服务的，所以作者通常设置<strong>CELERY_IGNORE_RESULT = True</strong>去丢弃。</p>
<p>对于我们来说，因为是异步任务，知道任务执行完成之后的状态真没啥用，所以果断丢弃。</p>
<h2 id="7，不要给任务传递_Database/ORM_对象">7，不要给任务传递 Database/ORM 对象</h2>
<p>这个其实就是不要传递Database对象（例如一个用户的实例）给任务，因为没准序列化之后的数据已经是过期的数据了。所以最好还是直接传递一个user id，然后在任务执行的时候实时的从数据库获取。</p>
<p>对于这个，我们也是如此，给任务只传递相关id数据，譬如文件转换的时候，我们只会传递文件的id，而其它文件信息的获取我们都是直接通过该id从数据库里面取得。</p>
<h2 id="最后">最后</h2>
<p>后面就是我们自己的感触了，上面作者提到的Celery的使用，真的可以算是很好地实践方式，至少现在我们的Celery没出过太大的问题，当然小坑还是有的。至于RabbitMQ，这玩意我们是真没用过，效果怎么样不知道，至少比mysql好用吧。</p>
<p>最后，附上作者的一个Celery Talk <a href="https://denibertovic.com/talks/celery-best-practices/" target="_blank" rel="external">https://denibertovic.com/talks/celery-best-practices/</a>。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-07-20T11:03:19.000Z"><a href="/2014/07/20/golang-func-vargs/">07-20-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/07/20/golang-func-vargs/">一个Go可变参数问题</a></h1>
  

    </header>
    <div class="entry">
      
        <p>几天前纠结了一个蛋疼的问题，在go里面函数式支持可变参数的，譬如…T，go会创建一个slice，用来存放传入的可变参数，那么，如果创建一个slice，例如a，然后以a…这种方式传入，go会不会还会新建一个slice，将a的数据全部拷贝一份过去？</p>
<p>如果a很大，那么将会造成很严重的性能问题，不过后来想想，可能是自己多虑了，于是查看go的文档，发现如下东西：</p>
<blockquote>
<p>Passing arguments to … parameters</p>
<p>If f is variadic with a final parameter p of type …T, then within f the type of p is equivalent to type []T. If f is invoked with no actual arguments for p, the value passed to p is nil. Otherwise, the value passed is a new slice of type []T with a new underlying array whose successive elements are the actual arguments, which all must be assignable to T. The length and capacity of the slice is therefore the number of arguments bound to p and may differ for each call site.</p>
<p>Given the function and calls</p>
<pre><code>func Greeting(prefix string, who ...string)
Greeting(&quot;nobody&quot;)
Greeting(&quot;hello:&quot;, &quot;Joe&quot;, &quot;Anna&quot;, &quot;Eileen&quot;)
</code></pre><p>within Greeting, who will have the value nil in the first call, and []string{“Joe”, “Anna”, “Eileen”} in the second.</p>
<p>If the final argument is assignable to a slice type []T, it may be passed unchanged as the value for a …T parameter if the argument is followed by …. In this case no new slice is created.</p>
<p>Given the slice s and call</p>
<pre><code>s := []string{&quot;James&quot;, &quot;Jasmine&quot;}
Greeting(&quot;goodbye:&quot;, s...)
</code></pre><p>within Greeting, who will have the same value as s with the same underlying array.</p>
</blockquote>
<p>也就是说，如果我们传入的是slice…这种形式的参数，go不会创建新的slice。写了一个简单的例子验证：</p>
<pre><code>package main

import &quot;fmt&quot;

func t(args ...int) {
    fmt.Printf(&quot;%p\n&quot;, args)
}

func main() {
    a := []int{1,2,3}
    b := a[1:]

    t(a...)
    t(b...)

    fmt.Printf(&quot;%p\n&quot;, a)
    fmt.Printf(&quot;%p\n&quot;, b)
}

//output
0x1052e120
0x1052e124
0x1052e120
0x1052e124
</code></pre><p>可以看到，可变参数args的地址跟实际外部slice的地址一样，用的同一个slice。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-06-22T13:29:26.000Z"><a href="/2014/06/22/program-lang-experience/">06-22-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/06/22/program-lang-experience/">我的编程语言经历</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Alan Perlis 说过：“一种不改变你编程的思维方式的语言，不值得去学。”，虽然写了这么多年程序，用了这么多的语言，但我自认还没悟道编程语言如何改变我的思维方式。</p>
<p>几天前，我需要用python来为<a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">ledisdb</a>写一个客户端，我突然发现，对于c++，go这种语言，我如果需要实现一个功能，首先想到的是问题是代码应该怎么写。但是当我使用python的时候，我首先考虑的问题是在哪里去找一个库用来解决我的问题。可能这就是使用不同语言带给我的不同思考方式吧。</p>
<p>我的编程语言经历没有那么复杂，没用过很多，但是其实也够我受的了，尤其是在不同语言语法糖之间切换的时候，有种让人崩溃的感觉。没准我应该升级一下我的大脑cpu，使其能够更快速的进行中断处理。</p>
<h2 id="c">c</h2>
<p>我是从大学才开始学习编程的，相比现在的小朋友来说，可以叫做输在了起跑线上面。谁叫以前生活在山区，没机会接触电脑这玩意。</p>
<p>我的第一门编程语言是c，不同于很多童鞋使用的谭浩强神书，我用的是周纯杰的&lt;<c语言程序设计>&gt;，不知道每年有多少同学受到过它的摧残，当然还有那哥们蹩脚的普通话。</c语言程序设计></p>
<p>在大学里面，很多同学的c的毕业设计都是我帮其完成，但我始终觉得自己仍然是个半吊子，除了c的基础稍微强一点之外，很多方面譬如操作系统，算法等完全不会。（现在随着工作年限的增加让我越发后悔，当初怎么就不稍微学点这些知识，尤其是编译原理。）</p>
<p>我几乎没怎么用c开发过项目，只在tencent可怜的维护过别人的c项目，但至少能看懂c代码，这就够了。</p>
<p>因为大多数时候，我用的是c++，而不是c来解决我的问题。</p>
<h2 id="c++">c++</h2>
<p>c++是我工作使用的第一门语言，也是我使用时间最长的一门语言，都七年之痒了，不过还是有点不离不弃的。</p>
<p>以前上学的时候有一句口头禅，叫学好c++，走遍天下都不怕。但是有几个人能把它学好的？所以千万别说自己精通c++，那会被人鄙视的。</p>
<p>我使用c++可以分为三个阶段：</p>
<h3 id="类c阶段">类c阶段</h3>
<p>这个阶段主要是我第一份工作的时候，那时候才毕业，c的烙印很深，面向对象除了有个概念，真正是啥完全不知道。所以最喜欢的方式还是写着一堆函数来解决问题，当初VIA身边那帮c++的牛人竟然能忍受我这样的代码，真佩服他们。</p>
<h3 id="面向对象阶段">面向对象阶段</h3>
<p>后来去了第二家公司linekong，开始做游戏，才开始真正意义上的用c++写代码了。</p>
<p>记得最开始去第一家公司面试的时候，被问了啥是面向对象，当时不假思索的答了继承，多态和封装。</p>
<p>啥叫封装？整一个class，把该包的都包了，一个同事曾告诉我，他见过有几万行代码的class，看来我这个几千行的太小儿科了。</p>
<p>啥叫继承？先来一个父类，干脆叫bird，有一个fly方法，再来一个子类，叫duck吧，继承了bird，不过duck会fly吗？一个父类不够，再来一个，搞个多重继承，什么？出现了菱形继承，那干脆在来一个virtual继承得了。</p>
<p>啥叫多态？不就是virtual function，然后父类指针能在运行时根据实际情况调用相应的子类实现。那c++的多态是怎么实现的？看看&lt;&lt;深度探索c++对象模型&gt;&gt;不就行了。</p>
<p>这段时间，可以算是我写c++代码最多的时候，都快写到吐了，尤其还要忍受那龟速的编译。我们竟然都实现了直接通过汇编改c++的虚表，使其调用自己的函数这种变态的东西。在那时候我就得出结论，如果不想早死，尽量别用这个东西写代码。可是到如今我都在不停的慢性自杀。</p>
<h3 id="现代C++阶段">现代C++阶段</h3>
<p>不知道从什么时候开始，我突然觉得我应该来点modern c++的编写方式了，c++0x都出了，还不玩一下就晚了。当然新特性那么多，不可能全部都拿来用的，Bjarne Stroustrup貌似都说过，c++0x应该算是另一门语言了。</p>
<p>于是哥就走上了伪modern c++之路，class还是需要的，不然数据怎么封装。继承吗，比重减轻吧，最好采用面向接口的编程方式。而多态，能不用就不用吧，反而觉得bing + function的方式实现的delegate模型反而更方便，没准也更酷哟。</p>
<p>shared_ptr，weak_ptr是需要用的了，c++没有gc，所以一套好的内存管理方式是必不可少的，每次new之后还要记得delete也比较烦，最严重的是可能忘记那就内存泄露了。</p>
<p>于是，我就自认为我进化了，最典型的例子就是我写的高性能网络库<a href="https://github.com/siddontang/libtnet" target="_blank" rel="external">libtnet</a>，感觉很modern了。</p>
<h2 id="lua">lua</h2>
<p>最开始知道lua，是云风那本编程感悟的书，当时可是菊花一紧，觉得这东西是啥，为什么能跟c结合到一起使用？</p>
<p>后来自己开发游戏了，才发现lua真的是一门很强大的语言，短小精悍，嵌入简单，性能超强，完全是作为游戏脚本语言开发的不二人选。不过我最开始使用lua的经历不怎么happy，最开始就是接手了一个c++与lua的粘合层库，关于这个库的传说，见这里<a href="http://blog.codingnow.com/2008/08/lua_is_not_c_plus_plus.html" target="_blank" rel="external">Lua 不是 C++</a>。后来，在踩了无数个坑，填了无数个坑之后，我终于弄得相对稳定了。貌似现在我以前的同事还在使用，不过正如我在<a href="http://blog.csdn.net/siddontang/article/details/18727645" target="_blank" rel="external">lua c函数注册器</a>中说明的那样，对于语言的交互，简单一点才好。现在以前做的游戏已经开源，见<a href="https://xp-dev.com/svn/YBTX_Public/" target="_blank" rel="external">这里</a>，那个传说中的蛋疼粘合层也见了世面。当然，我可不会告诉你们好多搓代码是我写的。</p>
<p>后来，在现在的公司，因为项目的需要，我们急需解决python的很多性能大坑问题，于是我开始推广使用openresty，一个用lua包裹的nginx，用了之后，腰不痛了，腿不痛了，性能妥妥的。</p>
<p>因为lua，我第一次尝到了在代码里面直接写配置的便捷，用一个table搞定，相比起来，c++处理ini，json这些的弱爆了。另外，动态语言的热更新机制使其代码升级异常方便，不过你得非常小心lua的闭包，没准你重新加载了代码运行还是老样子。</p>
<p>lua是一个动态语言，所以不用我们管内存释放问题，但是仍然可能会有引用泄露，在开发游戏的时候，为了解决我们程序lua内存泄露的问题，我曾经干过直接从_G递归遍历，扫描整个lua数据的事情。相比在c++使用valgrind这些程序的工具，lua配套的东西还是太小儿科了。</p>
<p>lua的调试也是一个大头问题，我曾今写过几个lua的调试器，例如<a href="https://github.com/siddontang/luahelper" target="_blank" rel="external">这个</a>，甚至都支持了类似gdb那样ctrl+c之后动态的设置断点，可是仍然没觉得比gdb方便，所以多数时候，我都是写log为主。</p>
<h2 id="python">python</h2>
<p>虽然小时候吃过很多蛇，但是蟒蛇可是从来没吃过的，现在看来python味道还不错。</p>
<p>我是来了kingsoft之后才开始正式使用python的。对于为啥使用python，我曾跟拉我进来的技术老大讨论过，他直接就说，开发快速，上手容易。</p>
<p>python开发的快速很大程度是建立在丰富的第三方库上面的，我们也使用了很多库，譬如tornado，gevent，django等，但是正如我最开始说的，因为我们有太多的选择，面对一个问题的时候，往往考虑的是如何选择一个库，而不是自己如何实现，这其实在某种程度上面使得很多童鞋知其然而不知其所以然。这点，lua可能是另一个极端，lua的定位在于嵌入式和高性能，所以自然地，你得自己动手造轮子（当然，现在也有很多好的第三方库了），虽然有时候写起来很不方便，但是至少自己很清楚程序怎么跑的。</p>
<p>当然，我绝对没有贬低python的意思，我很喜欢这门语言，用它来开发了很多东西，同时也知道很多公司使用python构建了很多大型稳定的系统（我们的产品应该也算吧）。</p>
<p>只是现在我越发觉得，看起来简单的语言，如果没有扎实的基本功底，写出来的东西也很烂，而python，恰恰给人放了一个很大的烟雾弹，你以为它有多容易，其实它是在玩你。</p>
<h2 id="go">go</h2>
<p>好了，终于开始说go了，let’s go！！！</p>
<p>我使用go的历史不长，可能也就一年多，但是它现在完全成了我最爱的语言，go具有了python开发的迅速，同时也有着c运行的性能。（当然，还是有差距的！）</p>
<p>网上有太多的语言之争，包括go，有人恨，有人爱。但萝卜白菜，各有所爱，对于我来说，能帮我解决问题，让我用着舒服的语言就是好语言。</p>
<p>go非常适用于服务端程序开发，比起用c++开发，我陡然觉得有一种很幸福的感觉，譬如对于网络编程，在c++里面，我需要自己写epoll的事件处理，而且这种异步的机制完全切分了整个逻辑，使得代码不怎么好写，我在开发<a href="https://github.com/siddontang/libtnet" target="_blank" rel="external">libtnet</a>的时候感触尤其深刻。但是在go里面，因为天生coroutine的支持，使得异步代码同步化了，非常利于代码的编写。</p>
<p>现在我的主要在项目中推动go的使用，我们已经用go搭建了一个高性能的推送服务器，后续还有几个系统会上线，而且开发的进度并不比使用python差，另外也很稳定，这让我对go的未来充满了期待。</p>
<p>我也用go写了很多的开源程序，也算是拿的出手了，譬如：</p>
<ul>
<li><a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">ledisdb</a>：一个基于leveldb的提供类似redis高级数据结果的高性能NoSQL，真挺绕口的，简单点就是一个高性能NoSQL。</li>
<li><a href="https://github.com/siddontang/mixer" target="_blank" rel="external">Mixer</a>：一个mysql-proxy，现在支持通用的mysql命令代理，读写分离，以及自动主备切换。后续将要参考vitess支持分区，为此一直在恶补编译原理的知识。</li>
<li><a href="https://github.com/siddontang/go-log" target="_blank" rel="external">go-log</a>：一个类似python log模块的东西，支持多种handler，以及不同的log级别。</li>
</ul>
<p>还有一些，可以参考我的<a href="https://github.com/siddontang" target="_blank" rel="external">github</a>，譬如<a href="https://github.com/siddontang/moonmq" target="_blank" rel="external">moonmq</a>（一个高性能push模型的消息服务器），<a href="https://github.com/siddontang/polaris" target="_blank" rel="external">polaris</a>（一个类似tornado的restful web框架），因为go，我开始热衷于开源了，并且认识了很多的好基友，这算得上一个很大的收获吧。</p>
<h2 id="其它">其它</h2>
<p>好了，说完了上面我的长时间使用语言（至少一年以上），我也用了很多其他的语言，现在虽然使用时间比较短，但不排除后续会长久使用。</p>
<h3 id="Objective-C">Objective-C</h3>
<p>因为我家终于有了苹果三件套，所以决定开发app了，首要的任务就是得学会使用Objective-C。我承认这真是一门奇葩的语言，如果没有xcode的自动补齐，我真不知道写起来是神马样的感觉。</p>
<p>而且第一次见到了一门推荐写函数名，变量名就像写文章的语言，至少我写c++，go这些的一个函数名字不会写成一个句子。</p>
<p>我现在在自学iOS的开发，慢慢在整出点东西，毕竟答应给老婆的iphone做点啥的。后续干脆就写一个《小白学iOS》系列blog吧（如果我有精力！），反正对于iOS，我真是一个小白。</p>
<h3 id="java">java</h3>
<p>好吧，我也在android上面写过程序，build到我的S3上面去过，对于java，我的兴趣真不大，貌似自己还买过两本《java编程思想》，那时候脑袋铁定秀逗了。</p>
<p>但是不得不承认，java在服务器领域具有非常强的优势，很多很多的大企业采用java作为其服务器的编程语言。典型的就是淘宝，据传杭州的很多软件公司都不用java的，你用java就等于给淘宝培养人才了。（不过我发现他们很多基础组件譬如TFS这些的可是c++的哟！）</p>
<p>java是门好语言，只是我个人不怎么喜欢，可能我就是太小众了，只对c语言体系的感兴趣。所以很多公司我去不了，哈哈！</p>
<h3 id="erlang">erlang</h3>
<p>受《计算机程序的构造与解释》影像，我一直想学一门函数式编程语言，最开始玩的是elisp，谁叫以前我是个深度的emacser（后来竟然变成了一个vimer，再后来就是sublimer，这世界真神奇）。</p>
<p>后来还是决定好好学习一下erlang，也第一次领略到了函数式编程的魅力。自己唯一用erlang开发过的东西就是bt下载的客户端，不过后来发现用处不大就没继续进行下去了。（好吧，我承认当时想下岛国的东西）</p>
<p>学习erlang之后最大的优势在于现在能看懂很多优秀的erlang项目，譬如我在做<a href="https://github.com/siddontang/moonmq" target="_blank" rel="external">moonmq</a>以及公司的推送服务的时候，研究了rabbitmq，这玩意可是用erlang写的，而我竟然还能看懂，太佩服我了。</p>
<h3 id="还有么？">还有么？</h3>
<p>想想自己还学了哪些语言？貌似没了，不知道awk算不算一门。看来我会得语言真不多。</p>
<h2 id="后续可能会学的">后续可能会学的</h2>
<p>逆水行舟，不进则退，计算机发展这么迅速，我也需要不断提升自己，其中学习一门新的语言可能是一个很好的提升途径，至少能为我打开一扇门。譬如，如果掌握了日文，就能更好的理解岛国片的精髓。我不会日文，所以还是个门外汉。</p>
<h3 id="ruby">ruby</h3>
<p>ruby是一门很优雅的语言，很多大神级别的人物推荐，github貌似也是ruby的幕后推手。</p>
<p>因为ROR的兴起，使得ruby更加流行。看来，一个好的框架库对于语言的推广帮助真挺大的。相比而言，python有django，tornado等，光选择适合自己的就得费点时间。</p>
<p>ruby可以算是一门完全面向对象的语言，连number这种的都是对象，而且看了几本Matz的书，觉得这哥们挺不错的，对技术的感悟很深，所以更让我有兴趣去了解ruby了。</p>
<h3 id="javascript">javascript</h3>
<p>作为一个技术人员，没一个自己的个人网站怎么行，我的阿里云都是包年买的（明年还是买国外的vps吧），自己的个人站点还无影无踪。</p>
<p>好吧，我完全不会javscript，看着css就头疼，没准我从一开始想自己写代码搭建个人站点这个步子就迈的太大，扯着蛋了。如果先用一个开源的框架搭建起来，再自己调整完善，可能会更好。但无论怎样，javascript这门语言还是要学习了解的，尤其是以后随着html5的流行，加之node.js疯狂流行，这门语言也会愈发的发光发热。</p>
<h3 id="C_Sharp">C Sharp</h3>
<p>其实本来不准备跟ms的东西扯上关系的，虽然vs是一个很强大的开发工具，但是我自从换成mac之后就不准备再迁回windows。</p>
<p>只是c#我可能是必须要学会的，因为那个坑爹的unity3d，虽然unity3d也提供了其它语言的支持（譬如伪javascript），但是大量的开发者还是选用了c#，至少在中国我问过很多朋友，都妥妥的用c#，既然这样，我也只能考虑学习使用了。</p>
<p>至于我为啥蛋疼的想玩unity3d，毕竟干了很多年游戏开发，一直有自己弄一个简单小游戏的梦想，还是妥妥的unity3d吧。</p>
<h3 id="自己造一个？">自己造一个？</h3>
<p>语言千千万，我不可能全部学会的，而且以后没准因为业务的需要，没准都会自己造一门语言，也就是DSL。不过这个貌似还离我比较遥远，编译原理的东西太差了（说多了都是泪呀）。自己写词法分析还成，后面就菜了。这也是<a href="https://github.com/siddontang/mixer" target="_blank" rel="external">Mixer</a>一直没啥进展的原因。不过已经买了龙书，在学习屠龙秘籍，希望成为顶尖高手吧。</p>
<h2 id="后记">后记</h2>
<p>写了这么多，看来随着年岁的增加，越来越啰嗦了。不是有一句古话：吾生也有涯，而知也无涯 。以有涯随无涯，殆已。不过不停地追逐不也是乐趣一件？</p>
<p>只是，现在我首先要做的就是向我老婆申请资金升级电脑了吧！</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-06-14T02:47:05.000Z"><a href="/2014/06/14/ledisdb-design-2/">06-14-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/06/14/ledisdb-design-2/">高性能NoSQL LedisDB设计2</a></h1>
  

    </header>
    <div class="entry">
      
        <p><a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">ledisdb</a>现在已经支持replication机制，为ledisdb的高可用做出了保障。</p>
<h2 id="使用">使用</h2>
<p>假设master的ip为10.20.187.100，端口6380，slave的ip为10.20.187.101，端口为6380.</p>
<p>首先我们需要master打开binlog支持，在配置文件中指定：</p>
<pre><code>use_bin_log : true
</code></pre><p>在slave的机器上面我们可以通过配置文件指定slaveof开启replication，或者通过命令slaveof显示的开启或者关闭。</p>
<pre><code>slaveof 10.20.187.100 6380
</code></pre><p>ledisdb的replication机制参考了redis以及mysql的相关实现，下面简单说明。</p>
<h2 id="redis_replication">redis replication</h2>
<p>redis的replication机制主要介绍在<a href="http://redis.io/topics/replication" target="_blank" rel="external">这里</a>，已经说明的很详细了。</p>
<ul>
<li>slave向master发送sync命令</li>
<li>master将其当前的数据dump到一个文件，同时在内存中缓存新增的修改命令</li>
<li>当数据dump完成，master就将其发送给slave</li>
<li>slave接受完成dump数据之后，将其本机先前的数据清空，然后在导入dump的数据</li>
<li>master再将先前缓存的命令发送给slave</li>
</ul>
<p>在redis2.8之后，为了防止断线导致重新生成dump，redis增加了psync命令，在断线的时候master会记住当前的同步状态，这样下次就能进行断点续传了。</p>
<h2 id="mysql_replication">mysql replication</h2>
<p>mysql的replication主要是通过binlog的同步来完成的。在master的任何数据更新，都会写入binlog，至于binlog的格式这里不再累述。</p>
<p>假设binlog的basename为mysql，index文件名字为mysql-bin.index，该文件记录着当前所有的binlog文件。</p>
<p>binlog有max file size的配置，当binlog写入的的文件大小超过了该值，mysql就会生成一个新的binlog文件。当mysql服务重启的时候，也会生成一个新的binlog文件。</p>
<p>在Percona的mysql版本中，binlog还有一个max file num的设置，当binlog的文件数量超过了该值，mysql就会删除最早的binlog。</p>
<p>slave有一个master.info的文件，用以记录当前同步master的binlog的信息，主要就是当前同步的binlog文件名以及数据偏移位置，这样下次重新同步的时候就能从该位置继续进行。</p>
<p>slave同步的数据会写入relay log中，同时在后台有另一个线程将relay log的数据存入mysql。</p>
<p>因为master的binlog可能删除，slave同步的时候可能会出现binlog丢失的情况，mysql通过<a href="http://dev.mysql.com/doc/refman/5.0/en/backup-policy.html" target="_blank" rel="external">dump+binlog</a>的方式解决，其实也就是slave完全的dump master数据，在生成的dump中也同时会记录当前的binlog信息，便于下次继续同步。</p>
<h2 id="ledisdb_replication">ledisdb replication</h2>
<p>ledisdb的replication机制参考了redis以及mysql，支持fullsync以及增量sync。</p>
<p>master没有采用aof机制，而是使用了binlog，通过指定max file size以及max file num用来控制binlog的总体大小，这样我就无需关心aof文件持续增大需要重新rewrite的过程了。</p>
<p>binlog文件名格式如下：</p>
<pre><code>ledis-bin.0000001
ledis-bin.0000002
</code></pre><p>binlog文件名的后缀采用数字递增，后续我们使用index来表示。</p>
<p>slave端也有一个master.info文件，因为ledisdb会严格的保证binlog文件后缀的递增，所以我们只需要记录当前同步的binlog文件后缀的index即可。</p>
<p>整个replication流程如下：</p>
<ul>
<li>当首次同步或者记录的binlog信息因为master端binlog删除导致不一致的时候，slave会发送fullsync进行全同步。</li>
<li>master收到fullsync信息之后，会将当前的数据以及binlog信息dump到文件，并将其发送给slave。</li>
<li>slave接受完成整个dump文件之后，清空所有数据，同时将dump的数据导入leveldb，并保存当前dump的binlog信息。</li>
<li><p>slave通过sync命令进行增量同步，sync命令格式如下：</p>
<pre><code>  sync binlog-index binlog-pos
</code></pre><p> master通过index定位到指定的binlog文件，并seek至pos位置，将其后面的binlog数据发送给slave。</p>
</li>
<li>slave接收到binlog数据，导入leveldb，如果sync没有收到任何新增数据，1s之后再次sync。</li>
</ul>
<p>对于最后一点，最主要就是一个问题，即master新增的binlog如何让slave进行同步。对于这点无非就是两种模型，push和pull。</p>
<p>对于push来说，任何新增的数据都能非常及时的通知slave去获取，而pull模型为了性能考虑，不可能太过于频繁的去轮询，略有延时。</p>
<p>mysql采用的是push + pull的模式，当binlog有更新的时候，仅仅通知slave有了更新，slave则是通过pull拉取实际的数据。但是为了支持push，master必须得维持slave的一些状态信息，这稍微又增加了一点复杂度。</p>
<p>ledisdb采用了非常简单的一种方式，定时pull，使用1s的间隔，这样既不会因为轮询太过频繁导致性能开销增大，同时也能最大限度的减少当机数据丢失的风险。</p>
<h2 id="总结">总结</h2>
<p>ledisdb的replication机制才刚刚完成，后续还有很多需要完善，但足以使其成为一个高可用的nosql选择了。</p>
<p>ledisdb的网址在这里<a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">https://github.com/siddontang/ledisdb</a>，希望感兴趣的童鞋共同参与。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-06-04T08:56:27.000Z"><a href="/2014/06/04/record-bugs/">06-04-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/06/04/record-bugs/">最近几个bug记录</a></h1>
  

    </header>
    <div class="entry">
      
        <p>记录最近出的几个bug</p>
<h2 id="connection_reset_by_peer">connection reset by peer</h2>
<p>最近服务器经常性的出现connection reset by peer的错误，开始我们只是以为小概率的网络断开导致的，可是随着压力的增大，每隔2分钟开始出现一次，这就不得不引起我们的重视了。</p>
<p>我们的业务很简单，lvs负责负载均衡（采用的是DR模式），keepalive timeout设置的为2分钟，后面支撑两台推送服务（后面叫做push），客户端首先通过lvs路由到某台push之后，频繁的向其发送推送消息。</p>
<p>客户端使用的是python request（底层基于urllib3），首先我很差异出了这样的错误竟然没有重试，因为写代码的童鞋告诉我会有重试机制的。于是翻了一下request的代码，竟然发现默认的重试是0，一下子碉堡了。</p>
<p>不过，即使改了重试，仍然没有解决reset by peer的问题。通常出现这种情况，很大的原因在于客户端使用的是keep alive长连接保活tcp，但是服务器端关闭了该连接。可是我们的服务器实现了定时ping的保活机制，应该也不会出现的。</p>
<p>然后我将目光投向了lvs，因为它的timeout设置的为2分钟，而reset by peer这个错误也是两分钟一个，所以很有可能就是我们的定时ping机制不起作用，导致lvs直接close掉了连接。</p>
<p>于是查看push自己的代码，陡然发现我们自己设置的定时ping的时间是3分钟，顿时无语了，于是立刻改成1分钟，重启push，世界清静了。</p>
<h2 id="ifconfig_overruns">ifconfig overruns</h2>
<p>push换上新的机器之后，（性能妥妥的强悍），我们竟然发现推送的丢包率竟然上升了，一下子碉堡了，觉得这事情真不应该发生的。通常这种情况发生在cpu处理网络中断响应不过来。但是我们可是妥妥的24核cpu，并且开启了irqbalance。</p>
<p>好不，用cat /proc/interrupts之后，发现所有的网卡中断都被cpu0处理了，irqbalance完全没有起作用。google之后发现，有些网卡在PCI-MSI模式下面irqbalance无效，而我们的网卡恰好是PCI-MSI模式的。</p>
<p>没办法，关停irqbalance，手动设置网卡中断的SMP_AFFINITY，一下子世界清静了。</p>
<h2 id="总结">总结</h2>
<p>可以发现，最近出的几次蛋疼的事情都是在运维层面上面出现的，实际测试也测不出来，碰到这样的问题，只能通过log这些的慢慢摸索排查了。当然也给了我一个教训，任何error级别的log都应该重视，不应该想当然的忽略。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-05-30T04:28:39.000Z"><a href="/2014/05/30/ledisdb-design-1/">05-30-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/05/30/ledisdb-design-1/">高性能NoSQL LedisDB设计1</a></h1>
  

    </header>
    <div class="entry">
      
        <p><a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">ledisdb</a>是一个用go实现的基于leveldb的高性能nosql数据库，它提供多种数据结构的支持，网络交互协议参考redis，你可以很方便的将其作为redis的替代品，用来存储大于内存容量的数据（当然你的硬盘得足够大！）。</p>
<p>同时ledisdb也提供了丰富的api，你可以在你的go项目中方便嵌入，作为你app的主要数据存储方案。</p>
<h2 id="与redis的区别">与redis的区别</h2>
<p>ledisdb提供了类似redis的几种数据结构，包括kv，hash，list以及zset，（set因为我们用的太少现在不予支持，后续可以考虑加入），但是因为其基于leveldb，考虑到操作硬盘的时间消耗铁定大于内存，所以在一些接口上面会跟redis不同。</p>
<p>最大的不同在于ledisdb对于在redis里面可以操作不同数据类型的命令，譬如（del，expire），是只支持kv操作的。也就是说，对于del命令，ledisdb只支持删除kv，如果你需要删除一个hash，你得使用ledisdb额外提供的hclear命令。</p>
<p>为什么要这么设计，主要是性能考量。leveldb是一个高效的kv数据库，只支持kv操作，所以为了模拟redis中高级的数据结构，我们需要在存储kv数据的时候在key前面加入相关数据结构flag。</p>
<p>譬如对于kv结构的key来说，我们按照如下方式生成leveldb的key：</p>
<pre><code>func (db *DB) encodeKVKey(key []byte) []byte {
    ek := make([]byte, len(key)+2)
    ek[0] = db.index
    ek[1] = kvType
    copy(ek[2:], key)
    return ek
}
</code></pre><p>kvType就是kv的flag，至于第一个字节的index，后面我们在讨论。   </p>
<p>如果我们需要支持del删除任意类型，可能的一个做法就是在另一个地方存储该key对应的实际类型，然后del的时候根据查出来的类型再去做相应处理。这不光损失了效率，也提高了复杂度。</p>
<p>另外，在使用ledisdb的时候还需要明确知道，它只是提供了一些类似redis接口，并不是redis，如果想用redis的全部功能，这个就有点无能为力了。</p>
<h2 id="db_select">db select</h2>
<p>redis支持select的操作，你可以根据你的业务选择不同的db进行数据的存放。本来ledisdb只打算支持一个db，但是经过再三考虑，我们决定也实现select的功能。</p>
<p>因为在实际场景中，我们不可能使用太多的db，所以select db的index默认范围就是[0-15]，也就是我们最多只支持16个db。redis默认也是16个，但是你可以配置更多。不过我们觉得16个完全够用了，到现在为止，我们的业务也仅仅使用了3个db。</p>
<p>要实现多个db，我们开始定了两种方案：</p>
<ul>
<li>一个db使用一个leveldb，也就是最多ledisdb将打开16个leveldb实例。</li>
<li>只使用一个leveldb，每个key的第一个字节用来标示该db的索引。</li>
</ul>
<p>这两种方案我们也不知道如何取舍，最后决定采用使用同一个leveldb的方式。可能我们觉得一个leveldb可以更好的进行优化处理吧。</p>
<p>所以我们任何leveldb key的生成第一个字节都是存放的该db的index信息。</p>
<h2 id="KV">KV</h2>
<p>kv是最常用的数据结构，因为leveldb本来就是一个kv数据库，所以对于kv类型我们可以很简单的处理。额外的工作就是生成leveldb对应的key，也就是前面提到的encodeKVKey的实现。</p>
<h2 id="Hash">Hash</h2>
<p>hash可以算是一种两级kv，首先通过key找到一个hash对象，然后再通过field找到或者设置相应的值。</p>
<p>在ledisdb里面，我们需要将key跟field关联成一个key，用来存放或者获取对应的值，也就是key:field这种格式。</p>
<p>这样我们就将两级的kv获取转换成了一次kv操作。</p>
<p>另外，对于hash来说，（后面的list以及zset也一样），我们需要快速的知道它的size，所以我们需要在leveldb里面用另一个key来实时的记录该hash的size。</p>
<p>hash还必须提供keys，values等遍历操作，因为leveldb里面的key默认是按照内存字节升序进行排列的，所以我们只需要找到该hash在leveldb里面的最小key以及最大key，就可以轻松的遍历出来。</p>
<p>在前面我们看到，我们采用的是key:field的方式来存入leveldb的，那么对于该hash来说，它的最小key就是<strong>“key:”</strong>，而最大key则是<strong>“key;”</strong>，所以该hash的field一定在<strong>“(key:, key;)”</strong>这个区间范围。至于为什么是<strong>“;”</strong>，因为它比<strong>“:”</strong>大1。所以<strong>“key:field”</strong>一定小于<strong>“key;”</strong>。后续zset的遍历也采用的是该种方式，就不在说明了。</p>
<h2 id="List">List</h2>
<p>list只支持从两端push，pop数据，而不支持中间的insert，这样主要是为了简单。我们使用key:sequence的方式来存放list实际的值。</p>
<p>sequence是一个int整形，相关常量定义如下：</p>
<pre><code>listMinSeq     int32 = 1000
listMaxSeq     int32 = 1&lt;&lt;31 - 1000
listInitialSeq int32 = listMinSeq + (listMaxSeq-listMinSeq)/2
</code></pre><p>也就是说，一个list最多存放1&lt;&lt;31 - 2000条数据，至于为啥是1000，我说随便定得你信不？</p>
<p>对于一个list来说，我们会记录head seq以及tail seq，用来获取当前list开头和结尾的数据。</p>
<p>当第一次push一个list的时候，我们将head seq以及tail seq都设置为listInitialSeq。</p>
<p>当lpush一个value的时候，我们会获取当前的head seq，然后将其减1，新得到的head seq存放对应的value。而对于rpush，则是tail seq + 1。</p>
<p>当lpop的时候，我们会获取当前的head seq，然后将其加1，同时删除以前head seq对应的值。而对于rpop，则是tail seq - 1。</p>
<p>我们在list里面一个meta key来存放该list对应的head seq，tail seq以及size信息。</p>
<h2 id="ZSet">ZSet</h2>
<p>zset可以算是最为复杂的，我们需要使用三套key来实现。</p>
<ul>
<li>需要用一个key来存储zset的size</li>
<li>需要用一个key:member来存储对应的score</li>
<li>需要用一个key:score:member来实现按照score的排序</li>
</ul>
<p>这里重点说一下score，在redis里面，score是一个double类型的，但是我们决定在ledisdb里面只使用int64类型，原因一是double还是有浮点精度问题，在不同机器上面可能会有误差（没准是我想多了），另一个则是我不确定double的8字节memcmp是不是也跟实际比较结果一样（没准也是我想多了），其实更可能的原因在于我们觉得int64就够用了，实际上我们项目也只使用了int的score。</p>
<p>因为score是int64的，我们需要将其转成大端序存储（好吧，我假设大家都是小端序的机器），这样通过memcmp比较才会有正确的结果。同时int64有正负的区别，负数最高位为1，所以如果只是单纯的进行binary比较，那么负数一定比正数大，这个我们通过在构建key的时候负数前面加”&lt;”，而正数（包括0）加”=”来解决。所以我们score这套key的格式就是这样：</p>
<pre><code>key&lt;score:member //&lt;0
key=score:member //&gt;=0
</code></pre><p>对于zset的range处理，其实就是确定某一个区间之后通过leveldb iterator进行遍历获取，这里我们需要明确知道的事情是leveldb的iterator正向遍历的速度和逆向遍历的速度完全不在一个数量级上面，正向遍历快太多了，所以最好别去使用zset里面带有rev前缀的函数。</p>
<h2 id="总结">总结</h2>
<p>总的来说，用leveldb来实现redis那些高级的数据结构还算是比较简单的，同时根据我们的压力测试，发现性能还能接受，除了zset的rev相关函数，其余的都能够跟redis保持在同一个数量级上面，具体可以参考ledisdb里面的性能测试报告以及运行ledis-benchmark自己测试。</p>
<p>后续ledisdb还会持续进行性能优化，同时提供expire以及replication功能的支持，预计6月份我们就会实现。</p>
<p>ledisdb的代码在这里<a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">https://github.com/siddontang/ledisdb</a>，希望感兴趣的童鞋共同参与。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-05-20T00:44:58.000Z"><a href="/2014/05/20/ledisdb-embed-introduction/">05-20-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/05/20/ledisdb-embed-introduction/">LedisDB嵌入使用介绍</a></h1>
  

    </header>
    <div class="entry">
      
        <p>ledisdb现在可以支持嵌入式使用。你可以将其作为一个独立的lib（类似leveldb）直接嵌入到你自己的应用中去，而无需在启动单独的服务。</p>
<p>ledisdb提供的API仍然类似redis接口。首先，你需要创建ledis对象：</p>
<pre><code>import &quot;github.com/siddontang/ledisdb/ledis&quot;

configJson = []byte(&#39;{
    &quot;data_db&quot; : 
    {
        &quot;path&quot; : &quot;/tmp/testdb&quot;,
        &quot;compression&quot;:true,
        &quot;block_size&quot; : 32768,
        &quot;write_buffer_size&quot; : 2097152,
        &quot;cache_size&quot; : 20971520
    }    
}
&#39;)

l, _ := ledis.Open(configJson)
</code></pre><p>data_db就是数据存储的leveldb位置，简单起见，所有的size配置全部使用byte作为单位。</p>
<p>然后我们选择一个db使用，</p>
<pre><code>db, _ := l.Select(0)
</code></pre><p>类似redis，我们也只支持数字类型的db，最多16个db，索引范围为[0-15]。支持太多的db真没啥意义。</p>
<p>下面是一些简单的例子：</p>
<h2 id="kv">kv</h2>
<pre><code>db.Set(key, value)
db.Get(key)
db.SetNX(key, value)
db.Incr(key)
db.IncrBy(key, 10)
db.Decr(key)
db.DecrBy(key, 10)

db.MSet(KVPair{key1, value1}, KVPair{key2, value2})
db.MGet(key1, key2)
</code></pre><h2 id="list">list</h2>
<pre><code>db.LPush(key, value1, value2, value3)
db.RPush(key, value4, value5, value6)

db.LRange(key, 1, 10)
db.LIndex(key, 10)

db.LLen(key)
</code></pre><h2 id="hash">hash</h2>
<pre><code>db.HSet(key, field1, value1)
db.HMSet(key, FVPair{field1, value1}, FVPair{field2, value2})

db.HGet(key, field1)

db.HGetAll()
db.HKeys()
</code></pre><h2 id="zset">zset</h2>
<pre><code>db.ZAdd(key, ScorePair{score1, member1}, ScorePair{score2, member2})

db.ZCard(key)

//range by score [0, 100], withscores = true and no limit
db.ZRangeByScore(key, 0, 100, true, 0, -1)

//range by score [0, 100], withscores = true and limit offset = 10, count = 10
db.ZRangeByScore(key, 0, 100, true, 10, 10)

db.ZRank(key, member1)

db.ZCount(key, member1)
</code></pre><p>ledisdb的源码在这里<a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">https://github.com/siddontang/ledisdb</a>，欢迎反馈。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-05-13T05:06:27.000Z"><a href="/2014/05/13/golang-in-procution-review/">05-13-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/05/13/golang-in-procution-review/">Go语言最佳实践</a></h1>
  

    </header>
    <div class="entry">
      
        <p>最近看了一篇关于go产品开发最佳实践的文章，<a href="http://peter.bourgon.org/go-in-production/" target="_blank" rel="external">go-in-procution</a>。作者总结了他们在用go开发过程中的很多实际经验，我们很多其实也用到了，鉴于此，这里就简单的写写读后感，后续我也争取能将这篇文章翻译出来。后面我用soundcloud来指代原作者。</p>
<h2 id="开发环境">开发环境</h2>
<p>在soundcloud，每个人使用一个独立的GOPATH，并且在GOPATH直接按照go规定的代码路径方式clone代码。</p>
<pre><code>$ mkdir -p $GOPATH/src/github.com/soundcloud
$ cd $GOPATH/src/github.com/soundcloud
$ git clone git@github.com:soundcloud/roshi
</code></pre><p>对于go来说，通常的工程管理应该是如下的目录结构：</p>
<pre><code>proj/
    src/
        modulea/
            a.go
        moudleb/
            b.go
        app/
            main.go
    pkg/
    bin/
</code></pre><p>然后我们在GOPATH里面将proj的路径设置上去，这样就可以进行编译运行了。这本来没啥，但是如果我们要将其代码提交到github，并允许另外的开发者使用，我们就不能将整个proj的东西提交上面，如果提交了，就很蛋疼了。外面的开发者可能这么引用：</p>
<pre><code>import &quot;github.com/yourname/proj/src/modulea&quot;
</code></pre><p>但是我们自己在代码里面就可以直接：</p>
<pre><code>import &quot;github.com/yourname/proj/modulea&quot;
</code></pre><p>如果外面的开发者需要按照去掉src的引用方式，只能把GOPATH设置到proj目录，如果import的多了，会让人崩溃的。</p>
<p>我曾今也被这事情给折腾了好久，终于再看了vitess的代码之后，发现了上面这种方式，觉得非常不错。</p>
<h2 id="工程目录结构">工程目录结构</h2>
<p>如果一个项目中文件数量不是很多，直接放在main包里面就行了，不需要在拆分成多个包了，譬如：</p>
<pre><code>github.com/soundcloud/simple/
    README.md
    Makefile
    main.go
    main_test.go
    support.go
    support_test.go
</code></pre><p>如果真的有公共的类库，在拆分成单独的包处理。</p>
<p>有时候，一个工程可能会包括多个二进制应用。譬如，一个job可能需要一个server，一个worker或者一个janitor，在这种情况下，建立多个子目录作为不同的main包，分别放置不同的二进制应用。同时使用另外的子目录实现公共的函数。</p>
<pre><code>github.com/soundcloud/complex/
README.md
Makefile
complex-server/
    main.go
    main_test.go
    handlers.go
    handlers_test.go
complex-worker/
    main.go
    main_test.go
    process.go
    process_test.go
shared/
    foo.go
    foo_test.go
    bar.go
    bar_test.go
</code></pre><p>这点我的做法稍微有一点不一样，主要是参考vitess，我喜欢建立一个总的cmd目录，然后再在里面设置不同的子目录，这样外面就不需要猜测这个目录是库还是应用。</p>
<h2 id="代码风格">代码风格</h2>
<p>代码风格这没啥好说的，直接使用gofmt解决，通常我们也约定gofmt的时候不带任何其他参数。</p>
<p>最好将你的编辑器配置成保存代码的时候自动进行gofmt处理。</p>
<p>Google最近发布了go的<a href="https://code.google.com/p/go-wiki/wiki/CodeReviewComments" target="_blank" rel="external">代码规范</a>，soundcloud做了一些改进：</p>
<ul>
<li>避免命名函数返回值，除非能明确的表明含义。</li>
<li>尽量少用make和new，除非真有必要，或者预先知道需要分配的大小。</li>
<li>使用struct{}作为标记值，而不是bool或者interface{}。譬如set我们就用map[string]struct{}来实现，而不是map[string]bool。</li>
</ul>
<p>如果一个函数有多个参数，并且单行长度很长，需要拆分，最好不用java的方式：</p>
<pre><code>// Don&#39;t do this.
func process(dst io.Writer, readTimeout,
    writeTimeout time.Duration, allowInvalid bool,
    max int, src &lt;-chan util.Job) {
    // ...
}
</code></pre><p>而是使用：</p>
<pre><code>func process(
    dst io.Writer,
    readTimeout, writeTimeout time.Duration,
    allowInvalid bool,
    max int,
    src &lt;-chan util.Job,
) {
    // ...
}
</code></pre><p>类似的，当构造一个对象的时候，最好在初始化的时候就传入相关参数，而不是在后面设置：</p>
<pre><code>f := foo.New(foo.Config{    
    Site: &quot;zombo.com&quot;,            
    Out:  os.Stdout,
    Dest: conference.KeyPair{
        Key:   &quot;gophercon&quot;,
        Value: 2014,
    },
})

// Don&#39;t do this.
f := &amp;Foo{} // or, even worse: new(Foo)
f.Site = &quot;zombo.com&quot;
f.Out = os.Stdout
f.Dest.Key = &quot;gophercon&quot;
f.Dest.Value = 2014
</code></pre><p>如果一些变量是后续通过其他操作才能获取的，我觉得就可以在后续设置了。</p>
<h2 id="配置">配置</h2>
<p>soundcloud使用go的flag包来进行配置参数的传递，而不是通过配置文件或者环境变量。</p>
<p>flag的配置是在main函数里面定义的，而不是在全局范围内。</p>
<pre><code>func main() {
    var (
        payload = flag.String(&quot;payload&quot;, &quot;abc&quot;, &quot;payload data&quot;)
        delay   = flag.Duration(&quot;delay&quot;, 1*time.Second, &quot;write delay&quot;)
    )
    flag.Parse()
    // ...
}
</code></pre><p>关于使用flag作为配置参数的传递，我持保留意见。如果一个应用需要特别多的配置参数，使用flag比较让人蛋疼了。这时候，使用配置文件反而比较好，我个人倾向于使用json作为配置，原因在<a href="http://blog.csdn.net/siddontang/article/details/23595817" target="_blank" rel="external">这里</a>。</p>
<h2 id="日志">日志</h2>
<p>soundcloud使用的是go的log日志，他们也说明了他们的log并不需要太多的其他功能，譬如log分级等。对于log，我参考python的log写了一个，在<a href="https://github.com/siddontang/golib/tree/master/log" target="_blank" rel="external">这里</a>。该log支持log级别，支持自定义loghandler。</p>
<p>soundcloud还提到了一个telemetry的概念，我真没好的办法进行翻译，据我的了解可能就是程序的信息收集，包括响应时间，QPS，内存运行错误等。</p>
<p>通常telemetry有两种方式，推和拉。</p>
<p>推模式就是主动的将信息发送给特定的外部系统，而拉模式则是将其写入到某一个地方，允许外部系统来获取该数据。</p>
<p>这两种方式都有不同的定位，如果需要及时，直观的看到数据，推模式是一个很好的选择，但是该模式可能会占用过多的资源，尤其是在数据量大的情况下面，会很消耗CPU和带宽。</p>
<p>soundcloud貌似采用的是拉模型。</p>
<p>关于这点我是深表赞同，我们有一个服务，需要将其信息发送到一个统计平台共后续的信息，开始的时候，我们使用推模式，每产生一条记录，我们直接通过http推给后面的统计平台，终于，随着压力的增大，整个统计平台被我们发挂了，拒绝服务。最终，我们采用了将数据写到本地，然后通过另一个程序拉取再发送的方式解决。</p>
<h2 id="测试">测试</h2>
<p>soundcloud使用go的testing包进行测试，然后也使用flag的方式来进行集成测试，如下：</p>
<pre><code>// +build integration

var fooAddr = flag.String(...)

func TestToo(t *testing.T) {
    f, err := foo.Connect(*fooAddr)
    // ...
}
</code></pre><p>因为go test也支持类似go build那种flag传递，它会默认合成一个main package，然后在里面进行flag parse处理。</p>
<p>这种方式我现在没有采用，我都是在测试用例里面直接写死了一个全局的配置，主要是为了方便的在根目录进行 go test ./…处理。不过使用flag的方式我觉得灵活性很大，后面如果有可能会考虑。</p>
<p>go的testing包提供的功能并不强，譬如没有提供assert_equal这类东西，但是我们可以通过reflect.DeepEqual来解决。</p>
<h2 id="依赖管理">依赖管理</h2>
<p>这块其实也是我非常想解决的。现在我们的代码就是很暴力的用go get来解决依赖问题，这个其实很有风险的，如果某一个依赖包更改了接口，那么我们go get的时候可能会出问题了。</p>
<p>soundcloud使用了一种vendor的方式进行依赖管理。其实很简单，就是把依赖的东西全部拷贝到自己的工程下面，当做自己的代码来使用。不过这个就需要定期的维护依赖包的更新了。</p>
<p>如果引入的是一个可执行包，在自己的工程目录下面建立一个_vendor文件夹（这样go的相关tool例如go test就会忽略该文件夹的东西）。把_vendor作为单独的GOPATH，例如，拷贝github.com/user/dep到_vendor/src/github.com/user/dep下面。然后将_vendor加入自己的GOPATH中，如下：</p>
<pre><code>GO ?= go
GOPATH := $(CURDIR)/_vendor:$(GOPATH)

all: build

build:
    $(GO) build
</code></pre><p>如果引入的是一个库，那么将其放入vendor目录中，将vendor作为package的前缀，例如拷贝github.com/user/dep到vendor/user/dep，并更改所有的相关import语句。</p>
<p>因为我们并不需要频繁的对这些引入的工程进行go get更新处理，所以大多数时候这样做都很值。</p>
<p>我开始的时候也采用的是类似的做法，只不过我不叫vendor，而叫做3rd，后来为了方便还是决定改成直接go get，虽然知道这样风险比较大。没准后续使用godep可能是一个不错的解决办法。</p>
<h2 id="构建和部署">构建和部署</h2>
<p>soundcloud在开发过程中直接使用go build来构建系统，然后使用一个Makefile来处理正式的构建。</p>
<p>因为soundcloud主要部署很多无状态的服务，类似Heroku提供了很简单的一种方式：</p>
<pre><code>$ git push bazooka master
$ bazooka scale -r &lt;new&gt; -n 4 ...
$ # validate
$ bazooka scale -r &lt;old&gt; -n 0 ...
</code></pre><p>这方面，我们直接使用一个简单的Makefile来构建系统，如下：</p>
<pre><code>all: build 

build:
    go install ${SRC}

clean:
    go clean -i ${SRC}

test:
    go test ${SRC} 
</code></pre><p>应用程序的发布采用最原始的scp到目标机器在重启的方式，不过现在正在测试使用salt来发布应用。而对于应用程序的启动，停止这些，我们则使用supervisor来进行管理。</p>
<h2 id="总结">总结</h2>
<p>总的来说，这篇文章很详细的讲解了用go进行产品开发过程中的很多经验，希望对大家有帮助。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-05-10T08:52:53.000Z"><a href="/2014/05/10/ledisdb-introduction/">05-10-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/05/10/ledisdb-introduction/">高性能NoSQL LedisDB介绍</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="起因">起因</h2>
<p><a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">ledisdb</a>是一个参考ssdb，采用go实现，底层基于leveldb，类似redis的高性能nosql数据库，提供了kv，list，hash以及zset数据结构的支持。</p>
<p>我们现在的应用极大的依赖redis，但随着我们用户量越来越大，redis的内存越来越不够用，并且replication可能还会导致超时问题。虽然后续我们可以通过添加多台机器来解决，但是在现有机器配置下面，我们仍希望单台机器承载更多的用户。另外，因为业务的特性，我们其实并不需要将所有的数据放到内存，只需要存放当前活跃用户。</p>
<p>经过我们的调研，发现ssdb已经很好的帮我们解决了这个问题，它提供了跟redis一致的接口（当然有些地方还是稍微不同），但是底层采用leveldb进行存储。根据其官网的描述，性能已经接近甚至超越了redis。</p>
<p>本着<a href="http://blog.csdn.net/siddontang/article/details/24765201" target="_blank" rel="external">造轮子</a>的精神，我决定用go实现一个类似的db，取名为ledisdb，也就是<strong>level-redis-db</strong>，为啥不用现成的ssdb，我觉得有如下几个原因：</p>
<ul>
<li>go语言开发的快速，这点毋庸置疑，虽然性能上面铁定离c++的代码有差距，但是我能够快速的进行原型搭建并实验。实际上，我在很短的时间里面就开发出了ledisdb，让我后续继续开发有了信心。</li>
<li>leveldb的研究，我一直很想将leveldb应用到我们的项目中，作为本机热点数据的首选数据存储方式，通过ledisdb，让我对leveldb的使用有了很多经验。</li>
<li>redis的熟悉，虽然我用了很久的redis，但是很多redis的命令仍然需要去查手册，通过实现ledisdb，我更加熟悉了redis的命令，同时，因为要了解这个命令redis如何实现，对redis内部又重新来了一次剖析。</li>
</ul>
<p>在准备开发ledisdb的时候，我就在思索一个问题，我需不需要开发另一个redis？其实这是一个很明确的问题，我不需要另一个redis。ledisdb虽然参考了redis，但为了实现简单，有时候我做了很多减法或者变更，譬如对于zset这种数据结构，我就只支持int64类型的score，而redis的score是double类型的，具体原因后续讲解zset的时候详细说明。</p>
<p>所以，我们可以认为，ledisdb是一个基于redis通信协议，提供了多种高级数据结构的nosql数据库，它并不是另一个redis。</p>
<h2 id="编译安装">编译安装</h2>
<p>因为ledisdb是用go写的，所以首先需要安装go以及配置GOROOT，GOPATH。</p>
<pre><code>mkdir $WORKSPACE
cd $WORKSPACE
git clone git@github.com:siddontang/ledisdb.git src/github.com/siddontang/ledisdb

cd src/github.com/siddontang/ledisdb

#构建leveldb，如果已经安装了，可忽略
./build_leveldb.sh  

#安装ledisdb go依赖
. ./bootstap.sh     

#配置GOPATH等环境变量
. ./dev.sh          

go install ./... 
</code></pre><p>具体的安装说明，可以查看代码目录下面的readme。</p>
<h2 id="Example">Example</h2>
<p>使用ledisdb很简单，只需要运行：</p>
<pre><code>./ledis-server -config=/etc/ledis.json
</code></pre><p>ledisdb的配置文件采用json格式，为啥选用json，我在<a href="http://blog.csdn.net/siddontang/article/details/23595817" target="_blank" rel="external">使用json作为主要的配置格式</a>里面有过说明。</p>
<p>我们可以使用任何redis客户端连接ledisdb，譬如redis-cli，如下：</p>
<pre><code>127.0.0.1:6380&gt; set a 1
OK
127.0.0.1:6380&gt; get a
&quot;1&quot;
127.0.0.1:6380&gt; incr a
(integer) 2
127.0.0.1:6380&gt; mset b 2 c 3
OK
127.0.0.1:6380&gt; mget a b c
1) &quot;2&quot;
2) &quot;2&quot;
3) &quot;3&quot;
</code></pre><h2 id="leveldb">leveldb</h2>
<p>因为leveldb是c++写的，所以在go里面需要使用，cgo是一种很好的方式。这里，我直接使用了<a href="https://github.com/jmhodges/levigo" target="_blank" rel="external">levigo</a>这个库，并在上面进行了封装，详见<a href="http://blog.csdn.net/siddontang/article/details/24359873" target="_blank" rel="external">这里</a>。虽然有一个go-leveldb，无奈仍不能用。</p>
<p>cgo的性能开销还是有的，这点在我做benchmark的时候就明显感觉出来，不过后续优化的空间很大，譬如将多个leveldb的调用逻辑该用c重写，这样只需要一次cgo就可以了。不过这个后续在考虑。</p>
<p>leveldb的一些参数在构建编译的时候是需要调整的，这点我没啥经验，只能google和参考ssdb。譬如下面这几个：</p>
<pre><code>+ db/dbformat.h

// static const int kL0_SlowdownWritesTrigger = 8;
static const int kL0_SlowdownWritesTrigger = 16;

// static const int kL0_StopWritesTrigger = 12;
static const int kL0_StopWritesTrigger = 64;

+ db/version_set.cc

//static const int kTargetFileSize = 2 * 1048576;
static const int kTargetFileSize = 32 * 1048576;

//static const int64_t kMaxGrandParentOverlapBytes = 10 * kTargetFileSize;
static const int64_t kMaxGrandParentOverlapBytes = 20 * kTargetFileSize;
</code></pre><p>相关参数的调优，只能等我后续深入研究leveldb了在好好考虑。</p>
<h2 id="性能测试">性能测试</h2>
<p>任何一个服务端服务没有性能测试报告那就是耍流氓，我现在只是简单的用了redis_benchmark进行测试，测试环境为一台快两年的老爷mac air机器。</p>
<p>测试语句：</p>
<pre><code>redis-benchmark -n 10000 -t set,incr,get,lpush,lpop,lrange,mset -q
</code></pre><p>redis-benchmark默认没有hash以及zset的测试，后续我在自己加入。</p>
<p>leveldb配置：</p>
<pre><code>compression       = false
block_size        = 32KB
write_buffer_size = 64MB
cache_size        = 500MB
</code></pre><h3 id="redis">redis</h3>
<pre><code>SET: 42735.04 requests per second
GET: 45871.56 requests per second
INCR: 45248.87 requests per second
LPUSH: 45045.04 requests per second
LPOP: 43103.45 requests per second
LPUSH (needed to benchmark LRANGE): 44843.05 requests per second
LRANGE_100 (first 100 elements): 14727.54 requests per second
LRANGE_300 (first 300 elements): 6915.63 requests per second
LRANGE_500 (first 450 elements): 5042.86 requests per second
LRANGE_600 (first 600 elements): 3960.40 requests per second
MSET (10 keys): 33003.30 requests per second
</code></pre><h3 id="ssdb">ssdb</h3>
<pre><code>SET: 35971.22 requests per second
GET: 47393.37 requests per second
INCR: 36630.04 requests per second
LPUSH: 37174.72 requests per second
LPOP: 38167.94 requests per second
LPUSH (needed to benchmark LRANGE): 37593.98 requests per second
LRANGE_100 (first 100 elements): 905.55 requests per second
LRANGE_300 (first 300 elements): 327.78 requests per second
LRANGE_500 (first 450 elements): 222.36 requests per second
LRANGE_600 (first 600 elements): 165.30 requests per second
MSET (10 keys): 33112.59 requests per second
</code></pre><h3 id="ledisdb">ledisdb</h3>
<pre><code>SET: 38759.69 requests per second
GET: 40160.64 requests per second
INCR: 36101.08 requests per second
LPUSH: 33003.30 requests per second
LPOP: 27624.31 requests per second
LPUSH (needed to benchmark LRANGE): 32894.74 requests per second
LRANGE_100 (first 100 elements): 7352.94 requests per second
LRANGE_300 (first 300 elements): 2867.79 requests per second
LRANGE_500 (first 450 elements): 1778.41 requests per second
LRANGE_600 (first 600 elements): 1590.33 requests per second
MSET (10 keys): 21881.84 requests per second
</code></pre><p>可以看到，ledisdb的性能赶redis以及ssdb还是有差距的，但也不至于不可用，有些差别并不大。至于为啥lrange比ssdb高，我比较困惑。</p>
<p>后续的测试报告，我会不断在benchmark文件里面更新。</p>
<h2 id="Todo。。。。。。">Todo。。。。。。</h2>
<p><a href="https://github.com/siddontang/ledisdb" target="_blank" rel="external">ledisdb</a>还是一个非常新的项目，比起ssdb已经在生产环境中用了很久，还有很多路要走，还有一些重要的功能需要实现，譬如replication等。</p>
<p>欢迎有兴趣的童鞋一起参与进来，在漫漫程序开发路上有一些好基友可是很幸运的。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-04-30T00:29:09.000Z"><a href="/2014/04/30/make-wheel/">04-30-2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/04/30/make-wheel/">谈谈自己造轮子</a></h1>
  

    </header>
    <div class="entry">
      
        <p>写下这篇文章，主要是对我近段时间工作的反思。</p>
<h1 id="为啥要造轮子">为啥要造轮子</h1>
<p>对于一些程序员来说，喜欢自己造轮子可算是一个很平常的事情，我想可能有如下原因：</p>
<ul>
<li>对于一些小的功能，不需要借助外部库，直接能够自己写完搞定。</li>
<li>对于一些大的功能，很多外部库不能很好的与自己项目整合，有时候还不如自己写一个。</li>
<li>有时候即使能用的外部库，因为程序员相轻的思想，就觉得自己写的nb，不用。</li>
<li>还有可能就是想深入学习某一个知识点，自己动手造一个。</li>
</ul>
<p>我不觉得造轮子不好，曾今很长一段时间我都认为造轮子是体现自己能力很好的一种方式，但是现在越来越觉得，不要过分的去造轮子。</p>
<h1 id="造轮子的教训">造轮子的教训</h1>
<p>昨天，我需要对接amazon s3的存储，官方没有go语言的sdk，所以我就动了自己写一个的想法，即使我知道铁定有第三方的实现。</p>
<p>amazon s3的接口因为都是restful形式，同时签名机制已经非常熟悉（国内的存储服务接口几乎都按照这套设计的，除了几个奇葩的公司），所以我就开始写了，写完了之后，我在看一个第三方的<a href="https://launchpad.net/goamz" target="_blank" rel="external">goamz</a>实现，发现跟我相差不了多少，一下子碉堡了。</p>
<p>我真的叫做没屁事了，这么浪费时间。</p>
<h1 id="造还是不造？">造还是不造？</h1>
<p>很多时候，我们要克服自己造轮子的冲动。</p>
<p>对于一个需要实现的功能，我觉得首先可以考虑该需求是否有成熟的解决方案，如果有，使用的成本有多大？</p>
<p>譬如对于python来说，如果我们现在需要一套web框架，如果自己去写，而不用成熟的tornado，django这些的，我真觉得蛋疼了。而对于go来说，我到现在还没发现我们用起来趁手的web框架，所以就有了自己造的<a href="https://github.com/siddontang/polaris" target="_blank" rel="external">polaris</a>。</p>
<p>如果项目进度有压力，多数时候我都倾向于通过集成外部解决方案来实现，而不是费时的自己去造轮子，因为这时候体现你能力的不是你写了多少nb的东西，而是将程序运行起来，提供服务。当然，你也不能找太挫的，或者完全无法驾驭的程序，那样后面就够你疼了。</p>
<p>即使真的需要自己去写一个轮子，还需要不停的问自己：我这个轮子稳定性如何，能否高效的运行，后续随着需求的变更我能不能很容易的掌控？如果发现自己搞不定，还是求助一下别人比较好。</p>
<p>如果我对某一个知识点特别有兴趣，想去深入研究并且有时间，那我觉得自己造几个轮子也算是很不错的事情。譬如我前段时间想重新深入了解网络编程，虽然有libev这些好用的开源库，我也基于他们封装了很多东西，譬如<a href="https://github.com/siddontang/tnet" target="_blank" rel="external">tnet</a>，<a href="https://github.com/siddontang/tpush" target="_blank" rel="external">tpush</a>，但是我仍然自己写了一个<a href="https://github.com/siddontang/libtnet" target="_blank" rel="external">libtnet</a>，写完了，我才有“啊哈，原来是这样“这种豁然开朗的感觉。</p>
<h1 id="写在后面">写在后面</h1>
<p>随着现在github这类网站的流行，找到高质量的第三方实现已经变成一件很容易的事情，作为一个程序员，不能固步自封，总认为我自己写的才是好的，有时候“自己动手，丰衣足食”这种想法反而会累死自己。</p>
<p>今天刚好看到了一篇文章<a href="http://it.deepinmind.com/%E5%85%B6%E5%AE%83/2014/04/29/knowing-the-bits.html" target="_blank" rel="external">一位码农的几点思考</a>，里面的观点我很赞同，与大家共勉。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/" class="alignleft prev">上一页</a>
  
  
    <a href="/page/3/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:siddontang.com">
  </form>
</div>

  <div class="widget tag">
  <h3 class="title">Github</h3>
  <ul class="entry">
  <li><a href="https://github.com/siddontang/ledisdb" target="_blank">LedisDB</a><small>Fast NoSQL</small></li>
  <li><a href="https://github.com/siddontang/mixer" target="_blank">Mixer</a><small>MySQL Proxy with Go</small></li>
  <li><a href="https://github.com/siddontang/libtnet" target="_blank">Libtnet</a><small>High Performance EventLoop</small></li>
  <li><a href="https://github.com/siddontang/moonmq" target="_blank">MoonMQ</a><small>Fast Message Queue</small></li>
  <li><a href="https://github.com/siddontang" target="_blank">More...</a></li>
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/c++/">c++</a><small>7</small></li>
  
    <li><a href="/categories/go/">go</a><small>28</small></li>
  
    <li><a href="/categories/leetcode/">leetcode</a><small>1</small></li>
  
    <li><a href="/categories/lua/">lua</a><small>2</small></li>
  
    <li><a href="/categories/mysql/">mysql</a><small>2</small></li>
  
    <li><a href="/categories/nginx/">nginx</a><small>2</small></li>
  
    <li><a href="/categories/program/">program</a><small>14</small></li>
  
    <li><a href="/categories/python/">python</a><small>6</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/tags/algorithm/" style="font-size: 10.00px;">algorithm</a><a href="/tags/c++/" style="font-size: 18.89px;">c++</a><a href="/tags/celery/" style="font-size: 10.00px;">celery</a><a href="/tags/docker/" style="font-size: 10.00px;">docker</a><a href="/tags/go/" style="font-size: 20.00px;">go</a><a href="/tags/gopkg/" style="font-size: 10.00px;">gopkg</a><a href="/tags/goroutine/" style="font-size: 10.00px;">goroutine</a><a href="/tags/json/" style="font-size: 10.00px;">json</a><a href="/tags/ledisdb/" style="font-size: 14.44px;">ledisdb</a><a href="/tags/leetcode/" style="font-size: 10.00px;">leetcode</a><a href="/tags/leveldb/" style="font-size: 10.00px;">leveldb</a><a href="/tags/libtnet/" style="font-size: 15.56px;">libtnet</a><a href="/tags/log/" style="font-size: 10.00px;">log</a><a href="/tags/lua/" style="font-size: 13.33px;">lua</a><a href="/tags/message-queue/" style="font-size: 10.00px;">message queue</a><a href="/tags/mixer/" style="font-size: 12.22px;">mixer</a><a href="/tags/moonmq/" style="font-size: 11.11px;">moonmq</a><a href="/tags/mysql/" style="font-size: 17.78px;">mysql</a><a href="/tags/nginx/" style="font-size: 11.11px;">nginx</a><a href="/tags/nosql/" style="font-size: 14.44px;">nosql</a><a href="/tags/polaris/" style="font-size: 11.11px;">polaris</a><a href="/tags/pprof/" style="font-size: 10.00px;">pprof</a><a href="/tags/proxy/" style="font-size: 10.00px;">proxy</a><a href="/tags/python/" style="font-size: 16.67px;">python</a><a href="/tags/reflect/" style="font-size: 10.00px;">reflect</a><a href="/tags/restful/" style="font-size: 10.00px;">restful</a><a href="/tags/rpc/" style="font-size: 10.00px;">rpc</a><a href="/tags/timer/" style="font-size: 11.11px;">timer</a><a href="/tags/timingwheel/" style="font-size: 10.00px;">timingwheel</a><a href="/tags/tornado/" style="font-size: 12.22px;">tornado</a><a href="/tags/zookeeper/" style="font-size: 10.00px;">zookeeper</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 SiddonTang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'siddontang';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>