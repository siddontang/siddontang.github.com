<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第 6 页 | 归档 | Siddon&#39;s Blog</title>
  <meta name="author" content="SiddonTang">
  
  <meta name="description" content="My thought for program">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Siddon&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Siddon&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27956076-1']);
  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Siddon&#39;s Blog</a></h1>
  <h2><a href="/">My thought for program</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/Presentations">Presentations</a></li>
    
      <li><a href="/About">About</a></li>
    
      <li><a href="/atom.xml">RSS</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
<h2 class="archive-title">归档</h2>


  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T10:28:23.000Z"><a href="/2013/12/28/libtnet-ioloop/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/libtnet-ioloop/">Libtnet事件循环</a></h1>
  

    </header>
    <div class="entry">
      
        <p>libtnet采用的是prefork + event loop的架构方式，prefork就是server在启动的时候预先fork多个子进程同时工作，而event loop则是基于epoll的事件处理机制。</p>
<p>在最新的linux系统中，提供了timerfd，eventfd，signalfd，加上原先的socket，大部分功能都可以抽象成io事件来处理了。而在libtnet中，这一切的基础就是IOLoop。</p>
<p>类似于tornado，libtnet的IOLoop也提供了相似的接口。其中最核心的就是以下三个：</p>
<pre><code>typedef std::function&lt;void (IOLoop*, int)&gt; IOHandler_t;

int addHandler(int fd, int events, const IOHandler_t&amp; handler);
int updateHandler(int fd, int events);
int removeHandler(int fd);  
</code></pre><p>对于任意的IO，我们可以注册感兴趣的事件（TNET_READ和TNET_WRITE），并绑定一个对应的callback回调。</p>
<p>callback的回调采用的是std::function的方式，这也就意味着，你可以在外部通过std::bind绑定任意不同的实现，再加上shared_ptr技术模拟闭包。</p>
<p>假设现在我们需要创建了一个socket对象，并将其添加到IOLoop中，我们可以这么做：</p>
<pre><code>std::shared_ptr&lt;Connection&gt; conn = std::make_shared&lt;Connection&gt;(socketfd);

ioloop-&gt;addHandler(socketfd, TNET_READ, std::bind(&amp;Connection::onHandler, conn, _1, _2));
</code></pre><p>这样，当该socket有读事件发生的时候，对应的onHandler就会被调用。在这里，我是用了shared_ptr技术，主要是为了方便进行对象生命周期的管理。</p>
<p>在上面的例子中，因为std::bind的时候引用了conn，只要不将socketfd进行removeHandler，conn对象就会一直存在。所以libtnet在IOLoop内部，自行维护了conn对象的生命周期。外面不需要在将其保存到另一个地方（如果真保存了该shared_ptr的conn，反而会引起内存泄露）。在libtnet的基础模块中，我都使用的是weak_ptr来保存相关对象，每次使用都通过lock来判定是否该对象存活。</p>
<p>在IOLoop内部，我使用一个vector来存放注册的handler，vector的索引就是io的fd。这样，我们通过io的fd就可以非常快速的查找到对应的handler了。为什么可以这样设计，是因为在linux系统中，进程中新建文件的file descriptor都是系统当前最小的可用整数。譬如，我创建了一个socket，fd为10，然后我关闭了该socket，再次新建一个socket，这时候新的socket的fd仍然为最小可用的整数，也就是10。</p>
<h1 id="EPoll">EPoll</h1>
<p>提到linux下面的高性能网络编程，epoll是一个铁定绕不开的话题，关于epoll的使用，网上有太多的讲解，这里就不展开了。</p>
<p>libtnet在Poller中集成了epoll，参考了libev的实现。epoll有两种工作模式，水平触发和边沿触发，各有利弊。libtnet使用的是水平触发方式，主要原因在于水平触发方式在有消息但是没处理的时候会一直通知你处理，实现起来不容易出错，也比较简单。</p>
<h2 id="fork_and_epoll_create">fork and epoll_create</h2>
<p>这里顺便记录一下我在实现prefork模型的时候遇到的一个坑。这个问题就是epoll fd应该在fork之前还是之后创建？</p>
<p>大家都知道，linux fork的时候采用COW（copy on write）方式复制父进程的内容，然后我想当然的以为各个子进程会拥有独立的epoll内核空间，于是在fork之前创建了epoll fd。但是后面我却惊奇的发现一个子进程对epoll的操作竟然会影响另一个子进程。也就是说，各个子进程共享了父进程的epoll内核空间。</p>
<p>所以，epoll fd的创建应该在fork之后，各个子进程独立创建。</p>
<h1 id="Example">Example</h1>
<h2 id="Timer">Timer</h2>
<p>IOLoop提供了一个简单的runAfter函数，用以实现定时器功能，使用非常简单：</p>
<pre><code>void func(IOLoop* loop)
{
    cout &lt;&lt; &quot;hello world&quot; &lt;&lt; endl;
    loop-&gt;stop();
}

IOLoop loop;
loop.runAfter(10 * 1000， std::bind(&amp;func, &amp;loop));
loop.start();
</code></pre><p>loop启动十秒之后，会打印hello world，然后整个loop退出。更多定制化的timer使用，可以使用libtnet提供的Timer class。</p>
<h2 id="Callback">Callback</h2>
<p>libtnet是一个单线程单ioloop的模型，但是不排除仍然会有其他线程希望与IOLoop进行通信，所以IOLoop提供了addCallback功能，这是libtnet唯一一个线程安全的函数。因为加入callback是一个很快速的操作，IOLoop使用了spinlock。在IOLoop每次循环的末尾，会将全部的callback取出，依次执行。</p>
<pre><code>void callback(IOLoop* loop)
{
    cout &lt;&lt; &quot;tell to exit&quot; &lt;&lt; endl;
    loop-&gt;stop();
}

IOLoop loop;
loop.addCallback(std::bind(&amp;func, &amp;loop));
loop.start();
</code></pre>
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T10:25:49.000Z"><a href="/2013/12/28/libtnet-introduction/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/libtnet-introduction/">高性能网络库Libtnet介绍</a></h1>
  

    </header>
    <div class="entry">
      
        <p>libtnet是一个用c++编写的高性能网络库，它在设计上面主要参考tornado，为服务端网络编程提供简洁而高效的接口，非常易于使用。</p>
<h1 id="Echo_Server">Echo Server</h1>
<pre><code>void onConnEvent(const ConnectionPtr_t&amp; conn, ConnEvent event, const void* context)
{
    switch(event)
    {
        case Conn_ReadEvent:
            {
                const StackBuffer* buffer = static_cast&lt;const StackBuffer*&gt;(context);
                conn-&gt;send(string(buffer-&gt;buffer, buffer-&gt;count));
            }
            break;
        default:
            break;
    }    
}

int main()
{
    TcpServer s;
    s.listen(Address(11181), std::bind(&amp;onConnEvent, _1, _2, _3));

    s.start();

    return 0;
}
</code></pre><p>当程序启动，服务监听本地11181端口，我们使用telnet测试：</p>
<pre><code>root@tnet:~# telnet 127.0.0.1 11181
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is &#39;^]&#39;.
hello world
hello world
</code></pre><p>可以看到，libtnet在使用上面非常简单，在listen的时候，指定一个回调函数，当有新的连接到来的时候，该回调函数就会与该connection进行绑定，这样该connection的任何事件都能通过回调进行处理。</p>
<p>在上面那个例子中，我们只关心了connection的ReadEvent，也就是读事件，然后将读取到的所有数据原封不动的转发回去。</p>
<h1 id="Http_Server">Http Server</h1>
<pre><code>void onHandler(const HttpConnectionPtr_t&amp; conn, const HttpRequest&amp; request)
{
    HttpResponse resp;
    resp.statusCode = 200;
    resp.body.append(&quot;Hello World&quot;);

    conn-&gt;send(resp);
}

int main()
{
    TcpServer s;
    HttpServer httpd(&amp;s);   
    httpd.setHttpCallback(&quot;/abc&quot;, std::bind(&amp;onHandler, _1, _2));

    httpd.listen(Address(11181));    
    s.start(4);

    return 0;
} 
</code></pre><p>当server启动，程序使用本机11181端口提供http服务。我们使用curl测试。</p>
<pre><code>curl http://127.0.0.1:11181/abc

return: hello world
</code></pre><p>可以看到，使用http server也非常简单，我们只需要对相应的路径绑定一个callback回调，当有请求发生的时候，对应的callback执行。</p>
<p>使用benchmark测试，发现性能也不错RPS能到16000+，在512MB，单核CPU下面进行ab压测，具体可以参考<a href="https://github.com/siddontang/libtnet/wiki/Benchmark" target="_blank" rel="external">benchmark</a>。</p>
<h1 id="Webscoket_Server">Webscoket Server</h1>
<pre><code>void onWsCallback(const WsConnectionPtr_t&amp; conn, WsEvent event, const void* context)
{
    switch(event)
    {
        case Ws_MessageEvent:
            {
                const string&amp; str = *(const string*)context;
                conn-&gt;send(&quot;hello &quot; + str);
            }
            break;
        default:
            break;
    }
}

int main()
{
    TcpServer s;

    HttpServer httpd(&amp;s);

    httpd.setWsCallback(&quot;/push/ws&quot;, std::bind(&amp;onWsCallback, _1, _2, _3));    

    httpd.listen(Address(11181));

    s.start();

    return 0; 
}
</code></pre><p>libtnet同样提供了websocket <a href="http://tools.ietf.org/html/rfc6455" target="_blank" rel="external">RFC6455</a>的支持，使用方法同http server，只需要对相应的path注册特定的回调，就可以很方便的进行websocket交互。</p>
<h1 id="Client">Client</h1>
<p>libtnet不光提供了server层面的相关功能，同时也集成了<strong>http client</strong>，<strong>websocket client</strong>以及<strong>redis client</strong>。使得libtnet也能方便的进行客户端网络功能的开发。对于具体的使用，可以参考<a href="https://github.com/siddontang/libtnet/tree/master/test" target="_blank" rel="external">example</a>。</p>
<h1 id="设计上面的考量">设计上面的考量</h1>
<p>libtnet只支持linux版本，虽然做一个跨平台的通用库是一件吸引力非常大的事情，但是综合考虑之后，我决定只做linux版本的，主要有以下几个原因：</p>
<ul>
<li>Linux下面使用prefork + epoll是一种非常高效的网络编程模型，性能强悍，实现简单。虽然unix下面有kqueue，windows下面有IOCP，但是没必要为了适配所有得操作系统将代码写的复杂。</li>
<li>Linux在系统层面上面就提供了很多高性能的函数，譬如timerfd，eventfd等，不光性能提升，同时也简化了很多代码实现。</li>
<li>Linux在服务器编程领域的使用率很高，专门做精一个平台就够了。</li>
</ul>
<p>因为高性能的网络编程通常都是使用异步的编程方式，所以经常可以看到代码被异步拆的特别分散，不利于编写。所以我在libtnet里面大量的使用了c++ bind以及shared_ptr技术，用来模拟函数闭包，以及解决对象生命周期管理问题，简化代码的编写。并且我也使用了c++ 0x相关技术，gcc的版本至少要在4.4以上。</p>
<p>对于如何设计以及使用libtnet，后续我会有更加详细的说明。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T10:24:58.000Z"><a href="/2013/12/28/mysql-index-point/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/mysql-index-point/">MySQL索引研究</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="介绍">介绍</h1>
<p>这段时间在重构server，尤其是重新设计表结构以满足功能需求以及后续的性能需求。因为我们使用的是mysql，所以为了支持更多的并发访问，对大数据量的表设计一些index是必不可少的，而现在看我当时设计的index，又发现了很多不足的地方。同时又因为深入重新在学习了解了一些index知识，觉得有必要记录一下，以免自己再犯同样的错误。</p>
<p>假设有如下的表结构，后续所有的例子都通过该表来说明：</p>
<pre><code>table tbl,
fileid int,
groupid int,
opver int,
name varchar(1024),
entid int,
primary key (fileid),
engine = innodb
</code></pre><h1 id="聚集索引">聚集索引</h1>
<p>因为使用的mysql engine是innodb，所以对于主键使用的是聚簇索引，对于聚簇索引我们知道它是吧数据存放到index里面的，也就是通过主键查询就能直接定位到数据，非常方便。</p>
<p>以前我受到的教育就是，select *是邪恶的，因为会取出所有列的数据。诚然，对于数据的获取，我们是按需索取，这样就能极大的减少网络传输的消耗。正因为以前有这样的认识，我自然认为innodb在server端io数据读取的时候也是按需索取。但其实不是这样。</p>
<p>在innodb里面，数据是按照页来存放的，通常一页为16k，每一页至少存放2条数据，也就是说，每一条数据在最大为8k。这里有童鞋就可能疑惑了，那如果我表结构里面有blob，text这种类型的肿么办？对于这种大数据类型的，innodb会将其存放到一个overflow page里面去，然后数据页只存放对应的指针。同样，innodb也是按照页来读取数据，也就是说一次读取16k。</p>
<p>对于上面我们的表结构，是完全能够存放到同一个page里面的，也就是说，我们即使select的时候没有选择对应的列，在innodb层面也仍然会将该数据读出，也就说无论怎样，io消耗是一样的。具体可以参考<a href="http://www.zhaokunyao.com/archives/1558" target="_blank" rel="external">这篇</a>。</p>
<p>这里在谈谈主键id类型选择的问题，因为innodb采用的是b+tree来进行数据的存储，网上对于是否采用自增id或者guid这种争论满天飞，现在我的想法如下：</p>
<ul>
<li>guid会导致主键过于分散，以至于在数据进行插入，删除，更新的时候会进行b+tree的频繁分裂，同时读取数据的时候因为过于分散会导致io随即读取，性能不高。</li>
<li>自增id虽然能让io进行顺序读取，但是如果服务器数据量太大造成分表了，对于每张表的auto increment的初始值维护也是一件很烦的事情。</li>
<li>鉴于上面那种情况，我们现在考虑的做法就是提供一个id生成器，用来保证主键的顺序递增，同时又保证全局的完全唯一。这个id生成器很容易，使用redis的incr就可以搞定，而且还可以通过incrby进行批量申请，性能妥妥的。</li>
</ul>
<h1 id="联合索引">联合索引</h1>
<p>一般为了查询方便，我们有可能在多列上面建立联合索引，譬如在(groupid, opver)上面，那么我就可以很方便的使用如下索引：</p>
<pre><code>select * from tbl where groupid in (1,2,3)
select * from tbl where groupid = 1 and opver &gt; 10 and opver &lt; 100
select * from tbl where groupid = 1 and opver &gt; 10 order by opver desc limit 10
</code></pre><p>在上面那些查询语句立马，index都能很好的工作，然后我就自认为下面这种的也行：</p>
<pre><code>select * from tbl where groupid in (1,2,3) and opver &gt; 10 order by opver desc limit 10
</code></pre><p>对于这个查询，我自然想到的就是首先mysql会通过索引选出groupid为1，2，3的，然后再在这个结果集里面选出opver满足的进行排序。可真的是这样吗。使用explain之后，才发现，在extra那一栏生生的出现了using filesort。也就是说mysql并没有对opver使用索引进行order by，而是使用了filesort，这里我们的索引在groupid之后就无效了。</p>
<p>其实这种情况可以用通用的情况来归纳，在一个组合索引里面，如果出现了多个范围查询，那么mysql不可能为每一个范围都使用索引，一般碰到第一个范围之后就会停止索引工作了。</p>
<p>这里给了我一个深刻的教训，就是设计好表结构以及index之后，不要自认为就能按照我想的方式工作了，最好需要explain一下，看看mysql到底是怎么工作的，不然出了性能瓶颈都不知道。</p>
<h1 id="覆盖索引">覆盖索引</h1>
<p>当我们需要查询的数据通过索引就能查到的时候，这种索引就叫做覆盖索引。譬如下面这些:</p>
<pre><code>select groupid, opver from tbl where groupid = 1 and opver &gt; 10;

select fileid, groupid, opver from tbl where groupid = 1 and opver &gt; 10 order by opver limit 10
</code></pre><p>因为我们在(groupid, opver)上面建立了索引，那么当我们查询的所有列包含在该索引里面的时候，我们就可以通过覆盖索引直接找到。通过explain可以看到extra里面有using index，表明使用了覆盖索引。</p>
<p>对于第二个例子，为什么fileid也可以使用覆盖索引呢，因为对于innodb来说，非聚簇索引保存的是主键id，也就是fileid，所以通过索引也能够直接找到fileid。</p>
<p>使用覆盖索引的好处是很明显的，数据只需要通过索引就能获取，而不需要通过主键在进行随机的io读取。一个很简单的例子。</p>
<pre><code>select entid from t1 order by opver limit 100000, 10;

select entid from t1 inner join (select fileid from t1 order by opver limit 100000, 10) as ac using(fileid)
</code></pre><p>因为我们需要查询entid，而没有任何一个索引能覆盖entid，这里我们给opver单独建立一个索引。对于第一个查询，mysql因为需要获取entid，所以会通过fileid查到实际的数据并取出，在进行排序，同时因为limit的跨度很大，mysql会丢弃很多数据，所以导致该查询会很慢。</p>
<p>而对于第二个查询，在join立马，我们只是通过覆盖索引找到了fileid，而不需要通过fileid去随机io读取实际数据，取出所有的fileid之后，在取出了entid。虽然该查询有一个join操作，但是因为join的性能很高，所以比第一个查询快很多。</p>
<p>关于索引覆盖，网上有很多关于这个的介绍，譬如<a href="http://hi.baidu.com/shinegun/item/1f36f5517bd8b4dfd48bac2d" target="_blank" rel="external">这个</a>，总之用好了覆盖索引，是能极大提升效率的，但是也不可能为了覆盖索引去建立覆盖索引，如果索引泛滥了，也是一件很头疼的事情。</p>
<h1 id="filesort">filesort</h1>
<p>对于先前联合索引遇到的问题，我发现如果不重新设计整个的查询机制，按照现有做法是完全不能避免filesort的。因为我们的业务逻辑就是需要查询一批groupid里面，opver大于某个值的所有数据。既然避免不了，那我们就可以看看到底性能高不高。</p>
<p>mysql对于filesort，有两种处理方式，一种是单路排序，一种是双路排序。单路排序直接就是取出选择的字段，然后在sort buffer中排序。而双路排序则是取出排序字段以及主键，排序完成之后在通过主键获取实际的数据。可以看出，双路排序会有两次io操作，自然性能会差一点。</p>
<p>早期mysql采用的是双路排序，现在采用的是单路，但是如果我们需要排序的数据超过了配置的sort buffer空间，或者需要排序的单行数据长度大于max_length_for_sort_data，mysql仍然会使用单路排序。mysql默认max_length_for_sort_data为1024，这个需要根据实际数据长度进行配置。</p>
<p>不过如果能把mysql的硬盘换成ssd，或者把内存加到100g以上，我觉得这个filesort也还真不成问题了。</p>
<h1 id="后续">后续</h1>
<p>这几天对于mysql索引的研究就先记录一下，感觉对mysql的理解还需要加深，后续如果还有什么新的感想也会在这里记录。同时bs一下自己，号称用了mysql这么多年，到现在了还有很多东西没有领会，是时候开始好好深入研究了。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T08:46:53.000Z"><a href="/2013/12/28/learn-tornado-asynchronous/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/learn-tornado-asynchronous/">学习Tornado：异步</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="why_asynchronous">why asynchronous</h1>
<p>tornado是一个异步web framework，说是异步，是因为tornado server与client的网络交互是异步的，底层基于io event loop。但是如果client请求server处理的handler里面有一个阻塞的耗时操作，那么整体的server性能就会下降。</p>
<pre><code>def MainHandler(tornado.web.RequestHandler):
    def get(self):
        client = tornado.httpclient.HttpClient()
        response = client.fetch(&quot;http://www.google.com/&quot;)
        self.write(&#39;Hello World&#39;)
</code></pre><p>在上面的例子中，tornado server的整体性能依赖于访问google的时间，如果访问google的时间比较长，就会导致整体server的阻塞。所以，为了提升整体的server性能，我们需要一套机制，使得handler处理都能够通过异步的方式实现。</p>
<p>幸运的是，tornado提供了一套异步机制，方便我们实现自己的异步操作。当handler处理需要进行其余的网络操作的时候，tornado提供了一个async http client用来支持异步。</p>
<pre><code>def MainHandler(tornado.web.RequestHandler):
    @tornado.web.asynchronous
    def get(self):
        client = tornado.httpclient.AsyncHTTPClient()
        def callback(response):
            self.write(&quot;Hello World&quot;)
            self.finish()

        client.fetch(&quot;http://www.google.com/&quot;, callback)
</code></pre><p>上面的例子，主要有几个变化：</p>
<ul>
<li>使用asynchronous decorator，它主要设置_auto_finish为false，这样handler的get函数返回的时候tornado就不会关闭与client的连接。</li>
<li>使用AsyncHttpClient，fetch的时候提供callback函数，这样当fetch http请求完成的时候才会去调用callback，而不会阻塞。</li>
<li>callback调用完成之后通过finish结束与client的连接。</li>
</ul>
<h1 id="asynchronous_flaw">asynchronous flaw</h1>
<p>异步操作是一个很强大的操作，但是它也有一些缺陷。最主要的问题就是在于callback导致了代码逻辑的拆分。对于程序员来说，同步顺序的想法是一个很自然的习惯，但是异步打破了这种顺序性，导致代码编写的困难。这点，对于写nodejs的童鞋来说，可能深有体会，如果所有的操作都是异步，那么最终我们的代码可能写成这样:</p>
<pre><code>def MainHandler(tornado.web.RequestHandler):
    @tornado.web.asynchronous
    def get(self):
        client = tornado.httpclient.AsyncHTTPClient()
        def callback1(response):

            def callback2(response):
                self.write(&quot;Hello World&quot;)
                self.finish()
            client.fetch(&quot;http://www.google.com&quot;, callback2)

        client.fetch(&quot;http://www.google.com/&quot;, callback1)
</code></pre><p>也就是说，我们可能会写出callback嵌套callback的情况，这个极大的会影响代码的阅读与流程的实现。</p>
<h1 id="synchronous">synchronous</h1>
<p>我个人认为，异步拆散了代码流程这个问题不大，毕竟如果一个逻辑需要过多的嵌套callback来实现的话，那么我们就需要考虑这个逻辑是否合理了，所以异步一般也不会有过多的嵌套层次。</p>
<p>虽然我认为异步的callback问题不大，但是如果仍然能够有一套机制，使得异步能够顺序化，那么对于代码逻辑的编写来说，会方便很多。tornado有一些机制来实现。</p>
<h2 id="yield">yield</h2>
<p>在python里面如果一个函数内部实现了yield，那么这个函数就不是函数了，而是一个生成器，它的整个运行机制也跟普通函数不一样，举一个例子:</p>
<pre><code>def test_yield():
    print &#39;yield 1&#39;
    a = yield &#39;yielded&#39;
    print &#39;over&#39;, a

t = test_yield()
print &#39;main&#39;, type(t)
ret = t.send(None)
print ret
try:
    t.send(&#39;hello yield&#39;)
except StopIteration:
    print &#39;yield over&#39;
</code></pre><p>输出结果如下：</p>
<pre><code>main &lt;type &#39;generator&#39;&gt;
yield 1
yielded
over hello yield
yield over
</code></pre><p>从上面可以看到，test_yield是一个生成器，当它第一次调用的时候，只是生成了一个Generator，不会执行。当第一次调用send的时候，生成器被resume，开始执行，然后碰到yield，就挂起，等待下一次被send唤醒。当生成器执行完毕，会抛出StopIteration异常，供外部send的地方知晓。</p>
<p>因为yield很方便的提供了一套函数挂起，运行的机制，所以我们能够通过yield来将原本是异步的流程变成同步的。</p>
<h2 id="gen">gen</h2>
<p>tornado有一个gen模块，提供了Task和Callback/Wait机制用来支持同步模型，以task为例：</p>
<pre><code>def MainHandler(tornado.web.RequestHandler):
    @tornado.web.asynchronous
    @tornado.gen.engine
    def get(self):
        client = tornado.httpclient.AsyncHTTPClient()
        response = yield tornado.gen.Task(client.fetch, &quot;http://www.google.com/&quot;)
        self.write(&quot;Hello World&quot;)
        self.finish()
</code></pre><p>可以看到，tornado的gen模块就是通过yield来进行同步化的。主要有如下需要注意的地方：</p>
<ul>
<li>使用gen.engine的decorator，该函数主要就是用来管理generator的流程控制。</li>
<li>使用了gen.Task，在gen.Task内部，会生成一个callback函数，传给async fetch，并执行fetch，因为fetch是一个异步操作，所以会很快返回。</li>
<li>在gen.Task返回之后使用yield，挂起</li>
<li>当fetch的callback执行之后，唤醒挂起的流程继续执行。</li>
</ul>
<p>可以看到，使用gen和yield之后，原先的异步逻辑变成了同步流程，在代码的阅读性上面就有不错的提升，不过对于不熟悉yield的童鞋来说，开始反而会很迷惑，不过只要理解了yield，那就很容易了。</p>
<h2 id="greenlet">greenlet</h2>
<p>虽然yield很强大，但是它只能挂起当前函数，而无法挂起整个堆栈，这个怎么说呢，譬如我想实现下面的功能:</p>
<pre><code>def a():
    yield 1

def b():
    a()

t = b()
t.send(None)
</code></pre><p>这个通过yield是无法实现的，也就是说，a里面使用yield，它是一个生成器，但是a的挂起无法将b也同时挂起。也就是说，我们需要一套机制，使得堆栈在任何地方都能够被挂起和恢复，能方便的进行栈切换，而这套机制就是coroutine。</p>
<p>最开始使用coroutine是在lua里面，它原生提供了coroutine的支持。然后在使用luajit的时候，发现内部是基于fiber(win)和context(unix)，也就是说，不光lua，其实c/c++我们也能实现coroutine。现在研究了go，也是内置coroutine，并且这里极力推荐一篇<a href="http://concur.rspace.googlecode.com/hg/talk/concur.html#table-of-contents" target="_blank" rel="external">slide</a>。</p>
<p>python没有原生提供coroutine，不知道以后会不会有。但有一个greenlet，能帮我们实现coroutine机制。而且还有人专门写好了tornado与greenlet结合的模块，叫做<a href="https://github.com/mopub/greenlet-tornado" target="_blank" rel="external">greenlet_tornado</a>，使用也很简单</p>
<pre><code>class MainHandler(tornado.web.RequestHandler):
    @greenlet_asynchronous
    def get(self):
        response = greenlet_fetch(&#39;http://www.google.com&#39;)
        self.write(&quot;Hello World&quot;)
        self.finish()
</code></pre><p>可以看到，使用greenlet，能更方便的实现代码逻辑，这点比使用gen更方便，因为这些连写代码的童鞋都不用去纠结yield问题了。</p>
<h1 id="总结">总结</h1>
<p>这里只是简单的介绍了tornado的一些异步处理流程，以及将异步同步化的一些方法。另外，这里举得例子都是网络http请求方面的，但是server处理请求的时候，可能还需要进行数据库，本地文件的操作，而这些也是同步阻塞耗时操作，同样可以通过异步来解决的，这里就不详细说明了。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T08:33:15.000Z"><a href="/2013/12/28/learn-tornado-security/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/learn-tornado-security/">学习Tornado：安全</a></h1>
  

    </header>
    <div class="entry">
      
        <p>在web编程中，安全性是我们都必须面临的一个问题，包括cookie伪造，xsrf攻击等。tornado作为一个web framework，在安全性方面也提供了很多功能，这里简单介绍一下。</p>
<h1 id="cookie">cookie</h1>
<p>在web编程中，浏览器经常使用cookie来保存相关用户信息，用于与server交互，但是cookie有很多安全问题，譬如cookie伪造。cookie有很多方式被修改，javascript，flash，以及browser plugin等，所以首先需要保证cookie不被修改。</p>
<h2 id="secure_cookie">secure cookie</h2>
<p>tornado提供了secure cookie机制来保证cookie不被修改。tornado使用一个密钥用来给cookie进行签名，用来保证cookie只能被服务器修改。因为密钥只有tornado server知道，所以其它应用程序是没办法修改cookie的值。</p>
<p>tornado使用set_secure_cookie和get_secure_cookie来设置和读取browser的cookie。使用secure cookie，只需要在tornado启动的时候设置cookie_secret就行了，如下：</p>
<pre><code>import tornado.web 
import tornado.httpserver 
import tornado.ioloop 

class MainHandler(tornado.web.RequestHandler):
    def get(self):
        count = self.get_secure_cookie(&#39;count&#39;)
        count = (int(count) + 1) if count else 1

        self.set_secure_cookie(&#39;count&#39;, str(count))

        self.write(str(count))

settings = {
    &#39;cookie_secret&#39; : &#39;S6Bp2cVjSAGFXDZqyOh+hfn/fpBnaEzFh22IVmCsVJQ=&#39;
}

application = tornado.web.Application([
    (r&quot;/&quot;, MainHandler),
], **settings)

http_server = tornado.httpserver.HTTPServer(application)
http_server.listen(8080)
tornado.ioloop.IOLoop.instance().start()
</code></pre><p>cookie_secret的生成如下：</p>
<pre><code>import base64
import uuid
base64.b64encode(uuid.uuid4().bytes + uuid.uuid4().bytes)
</code></pre><h2 id="httponly">httponly</h2>
<p>为了防止cross-site scripting attack，tornado可以再设置cookie的时候增加httponly字段，这样该cookie就不能够被javascript读取。同时，为了更高的安全性，可以给cookie设置secure属性，这个跟先前讨论的set_secure_cookie不一样，上面那个是对cookie进行加密签名，保证不被修改，而这个则是让browser通过ssl传输cookie。启用这些功能很简单，只需要在设置cookie的时候处理。</p>
<pre><code>class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.set_cookie(&#39;count1&#39;, &#39;1&#39;, httponly = True, secure = True)
        self.set_secure_cookie(&#39;count2&#39;, &#39;2&#39;, httponly = True, secure = True)
</code></pre><h1 id="XSRF">XSRF</h1>
<p>上面介绍的方法虽然能够保证cookie的安全，但是还是防止不了<a href="http://en.wikipedia.org/wiki/Cross-site_request_forgery" target="_blank" rel="external">XSRF攻击</a>。为了防止XSRF攻击，首先设计web服务的时候就需要考虑http method的side effects。按照restful的编程模型，get只能用来获取数据，post才会去修改数据，这样就能在很大的程度上面防止XSRF，因为对于通常情况来说，XSRF攻击就是通过设置img的src为一个恶意的get请求，只要我们的get不会进行数据修改，自然就能防止。</p>
<p>但是一些恶意的操作仍然能够发送post请求来进行攻击，譬如通过HTML forms或者XMLHTTPRequest API，所以为了防止post这种的攻击，我们需要一些额外的机制。</p>
<p>tornado提供了一个XSRF保护机制，原理很简单，就是在post提交数据的时候额外加入一个_xsrf字段，这个字段的值是从secure cookie里面获取的，因为其它的应用程序获取不到这个cookie的值，所以我们能够保证post的安全性。开启xsrf protection也很简单。</p>
<pre><code>settings = {
    &#39;cookie_secret&#39; : &#39;S6Bp2cVjSAGFXDZqyOh+hfn/fpBnaEzFh22IVmCsVJQ=&#39;,
    &#39;xsrf_cookies&#39; : True
}

application = tornado.web.Application([
    (r&quot;/&quot;, MainHandler),
    (r&quot;/purchase&quot;, PurchaseHandler)
], **settings)
</code></pre><p>在post提交的form里面，我们只需要设置如下：</p>
<pre><code>&lt;form action=&quot;/purchase&quot; method=&quot;POST&quot;&gt;

    &lt;input type=&quot;submit&quot; value=&quot;同意&quot; name=&quot;agree&quot;/&gt;
&lt;/form&gt;
</code></pre><h1 id="User_Authentication">User Authentication</h1>
<p>tornado还提供了用户认证功能，当用户登录之后，会将用户的相关信息保存到一个地方，通常是在cookie里面。当用户的cookie过期，再次访问web服务的时候就会被重定向到登陆页面。</p>
<p>要实现上述功能，只需要重载get_current_user函数，配置login_url和使用authenticated decorator就行了。如下：</p>
<pre><code>class BaseHandler(tornado.web.RequestHandler):
    def get_current_user(self):
        return self.get_secure_cookie(&#39;username&#39;)

class LoginHandler(BaseHandler):
    def get(self):
        str = &#39;&#39;&#39;&lt;body&gt;&lt;form action=&quot;/login&quot; method=&quot;POST&quot;&gt;
                UserName: &lt;input type=&quot;text&quot; name=&quot;username&quot; /&gt;
                          &lt;input type=&quot;submit&quot; value=&quot;Login&quot; /&gt;
                &lt;/form&gt;&lt;/body&gt;&#39;&#39;&#39;
        self.write(str)

    def post(self):
        self.set_secure_cookie(&#39;username&#39;, self.get_argument(&#39;username&#39;))
        self.redirect(&#39;/&#39;)

class MainHandler(BaseHandler):
    @tornado.web.authenticated
    def get(self):
        user = self.current_user
        self.write(&#39;hello &#39; + user)

class LogoutHandler(BaseHandler):
    def get(self):
        self.clear_cookie(&#39;username&#39;)
        self.redirect(&#39;/&#39;)

settings = {
    &#39;cookie_secret&#39; : &#39;S6Bp2cVjSAGFXDZqyOh+hfn/fpBnaEzFh22IVmCsVJQ=&#39;,
    &#39;login_url&#39; : &#39;/login&#39;
}

application = tornado.web.Application([
    (r&#39;/&#39;, MainHandler),
    (r&#39;/login&#39;, LoginHandler),
    (r&#39;/logout&#39;, LogoutHandler)
], **settings)

http_server = tornado.httpserver.HTTPServer(application)
http_server.listen(8080)
tornado.ioloop.IOLoop.instance().start()
</code></pre><h1 id="总结">总结</h1>
<p>web安全一直是一个非常严重的问题，我们在写代码的时候一定要注意，这里有一篇如何写安全web的<a href="https://wiki.mozilla.org/WebAppSec/Secure_Coding_Guidelines" target="_blank" rel="external">Guide</a>。tornado虽然提供了一些安全机制，但是仍然不能完全保证绝对安全性，所以很多时候就需要我们决定我所写的服务到底应该有什么样的安全级别，从在这个级别下面如何保证安全性就可以了。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T08:21:20.000Z"><a href="/2013/12/28/lua-debuger/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/lua-debuger/">Lua Debugger开发</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="introduction">introduction</h1>
<p>工欲善其事，必先利其器。lua作为一门动态语言，虽然我已经习惯了使用print来进行代码调试，但是还是有很多童鞋觉得一款好用的调试器能更好的进行lua代码编写。所以在接手游戏的lua结合层之后，自然就需要提供一个debuger工具了。</p>
<p>我们只需要的是一个能快速进行lua代码调试的工具，所以不需要gdb那种额外复杂的功能，只需要提供几种简单的功能就行了，如下：</p>
<ul>
<li>c/continue   继续执行</li>
<li>bt/backtrace 列出当前堆栈</li>
<li>f/frame n    跳转到frame n</li>
<li>l/list b e   列出源代码，b为起始行，e为结束行</li>
<li>p/print v    打印v的值</li>
<li>n/next       执行，跳过下一行，包括跳过子函数</li>
<li>s/step       执行，直到碰到不同的一行</li>
<li>return       执行，直到该函数结束</li>
</ul>
<p>虽然调试器实现的功能很简单，但是对于大多数应用来说，已经完全足够使用。</p>
<h1 id="lua_debug_library">lua debug library</h1>
<p>lua提供了一个debug library，我们就通过这个库来实现一个调试器。<br>首先，我们需要注册一个lua debug hook，并且绑定LUA_MASKLINE，LUA_MASKRET，LUA_MASKCALL事件，这样当lua代码执行的时候如果碰到相应的事件，则会调用我们注册的debug hook。</p>
<p>当debug hook调用的时候，程序就进入debug模式，这时候就可以输入对应的命令进行执行。</p>
<h1 id="db">db</h1>
<p>只要注册了debug hook，那么每次lua代码执行的时候碰到对应的事件就会调用注册hook，如果每次调用都进入debug模式，那是很影响程序运行的，所以我们需要一种机制，只在需要的时候进入debug模式。</p>
<p>在gdb里面，我们通过设置断点来进入可调式模式，虽然在lua里面也可以这么做，但这里我们采用了一种更简单的方法。我们给lua注册一个db函数，当lua执行到db函数的时候，程序才会进入debug模式。因为lua是动态语言，如果我们需要在另一个地方也进行调试，只需要再次加入db函数，重启程序即可。</p>
<p>所以这里我们debug hook函数内部实现是一个状态机，当没有进入db的时候，虽然lua也会进行调用该hook，但该hook内部不作任何处理。只有当执行db函数进入debug模式，hook内部才会有相应处理。</p>
<p>我们在debug hook里面提供了多种状态，包括none hook，step hook，next hook和return hook。</p>
<ul>
<li>none hook，没有进入debug模式，该hook不做任何处理</li>
<li>step hook，进入debug的step模式，当lua代码执行到新的一行代码时候做处理</li>
<li>next hook，进入debug的next模式，当lua代码跳过下一行时候做处理</li>
<li>return hook，进入debug的return模式，当lua执行到当前函数退出时候做处理</li>
</ul>
<h1 id="continue">continue</h1>
<p>continue会让程序继续执行。该命令会让hook切入none hook状态，直到下次lua执行db函数进入debug模式。</p>
<h1 id="step">step</h1>
<p>step会让hook切入step hook状态，该hook会监听LUA_MASKLINE事件，当该事件发生时候，step hook进行处理，打印当前代码，并再次进入debug模式，供下次命令输入。</p>
<h1 id="next">next</h1>
<p>next会让hook切入next hook状态，该hook也会监听LUA_MASKLINE事件，但是next跟step最大的区别在于next是跳过一行，也就是说如果执行的lua代码下一行是一个函数调用，step会进入函数内部，而next则会执行该函数，并跳过该函数这一行直到下一行。</p>
<p>所以next需要进行判断LUA_MASKLINE是否进入了一个新的函数，这里我们通过函数堆栈深度来进行，当lua代码执行到一个新的函数的时候，它的函数堆栈深度会加1，所以我们只需要记录当前的堆栈深度a，next执行到下一次LUA_MASKLINE时候，获取堆栈深度b，如果a小于b，那么表明进入了一个新的函数，所以我们不需要处理，直到再次获取的堆栈深度等于a。</p>
<h1 id="return">return</h1>
<p>return会让hook切入return hook状态，该hook会监听LUA_MASKRET事件，当该事件发生，return hook进行处理。这里我们仍然需要进入是否进入新函数调用的判断，因为我们只想监听的是当前函数的LUA_MASKRET事件，所以我们仍需要像next那样进行堆栈深度的判断。</p>
<h1 id="backtrace/frame/list">backtrace/frame/list</h1>
<p>backtrace，frame，list这几个命令这里列在一起，是因为他们都跟lua_getstack，lua_getinfo这两个函数有关系。我们通过lua_getstack初始化指定栈帧的lua_Debug结构，然后在通过调用lua_getinfo获取相关栈帧信息。</p>
<h1 id="print_value">print value</h1>
<p>print value命令可能算是最复杂的一个命令，因为有多个逻辑处理。当我们通过frame定位到某一层栈帧之后，就可以通过print打印相关的对象数据，供调试使用。</p>
<p>当print value的时候，首先我们查找value是否在当前函数里面local变量里面，如果没有则查找该函数的upvalue，如果仍然没有，则查找global，如果都没找到，则输出nil。</p>
<h1 id="code">code</h1>
<p>代码在<a href="https://github.com/siddontang/luahelper" target="_blank" rel="external">luahelper</a>的debughelper，只是一个简单的实现，还有一些问题需要考虑。</p>
<p>因为lua的debug hook注册的时候只能提供一个hook，所以为了简单起见，我对DebugHelper使用了单例模式，但是最好是一个lua实例对应一个debuger。要做到这样，自己想到了两种可能方法:</p>
<ul>
<li>使用LUAI_EXTRASPACE，并通过luai_userstateopen，luai_userstateclose将debuger绑定到lua实例上面，并通过luai_userstatethread进行debuger在coroutine的迁移。这种方法需要重新编译lua代码，适合集成lua源码的项目。</li>
<li>debuger内部使用一个map来进行对应，但是在lua里面需要替换coroutine的创建，因为创建的coroutine也需要对应到同一个debuger上面。</li>
</ul>
<p>两种方法都懒得弄了，以后有机会去尝试一下。</p>
<h1 id="end">end</h1>
<p>这里只是简单的实现了一个lua debuger，但是功能我觉得足以可以在实际项目中应用了。只是越来觉得，对于动态语言，print和log才是我最喜欢的代码调试方式，因为简单而且强迫你去思考整个程序的运行流程。不过把debuger放在这里，也算是对自己以前游戏开发的一个总结吧。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-12-28T08:21:04.000Z"><a href="/2013/12/28/bin-packer/">12-28-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/12/28/bin-packer/">bin packer制作</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="起因">起因</h1>
<p>一年前接触texture packer的时候，就一直有做一个类似工具的想法，当时想了一下，可以从以下几个方面入手：</p>
<ul>
<li>界面与功能分离，也就是提供命令行功能，界面直接通过命令行调用实现相关功能。界面可以考虑使用qt或者wxwidget。</li>
<li>实现一个高效的packer算法</li>
<li>图像处理问题，读入不同格式的文件，输出设定格式的文件，这个可以使用GraphicsMagick来处理。</li>
</ul>
<p>那么首要实现的其实就是一个好的packer算法。而对于图像处理，以及界面展示，这些我觉得都可以在后期考虑。</p>
<p>虽然当时很有想做一个的冲动，但因为很多原因，停滞了下来。不过心里总有一个坎，直到现在又重新接触了cocos2d-x，立马觉得要实现这个packer了。</p>
<h1 id="bin_packing_problem">bin packing problem</h1>
<p>我们需要实现的功能就是把一批小的texture合并到一张大的texture上面，而这个就是bin packing problem需要解决的问题。</p>
<p>参考了很多资料，譬如<a href="http://codeincomplete.com/posts/2011/5/7/bin_packing/" target="_blank" rel="external">这个</a>，<a href="http://www.codeproject.com/Articles/210979/Fast-optimizing-rectangle-packing-algorithm-for-bu" target="_blank" rel="external">这个</a>，还有<a href="http://www.blackpawn.com/texts/lightmaps/default.html" target="_blank" rel="external">这个</a>。</p>
<p>理解了基本算法之后，自己也实现了很简单的<a href="https://gist.github.com/4168873" target="_blank" rel="external">packer</a>。大概原理也很简单:</p>
<ul>
<li>将所有texture从大到小排序，可以按照maxsize，area，width，height等。</li>
<li>取出第一个texture，初始化root bin的大小为该texture大小。</li>
<li>取出第二个texutre，通过root查找是否有bin能将其放下，如果能放下，则放入，并将该bin切分。</li>
<li>如果没有可以放下的bin，则扩容root bin，并将原先root bin作为扩大bin之后的子节点，扩容bin设为root bin</li>
<li>重复执行上述3，4，直到所有的texture都放入</li>
</ul>
<p>具体流程可以参考代码。</p>
<h1 id="总结">总结</h1>
<p>总的来说，实现一个简单的bin packer是比较简单的，当然还有很多复杂的实现，只是对于一般应用来说，足够了。这里还需要赞一下python，快速开发原型实在是太方便了。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-06-20T12:23:33.000Z"><a href="/2013/06/20/certificate-csp-openssl/">06-20-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/06/20/certificate-csp-openssl/">证书，CSP与Openssl</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="起因">起因</h2>
<p>最近在研究更安全的交互体系，自然想到的就是提供证书的交互方式。给用户分配一对公私钥，然后将私钥交给用户保管，用户在登录或者一些关键操作的时候通过私钥签名，从而保证其安全性。</p>
<p>鉴于团队的童鞋都没有开发usb key相关的经验，所以最开始的版本只考虑通过软证书实现。为了保证安全性，我们将用户的证书信息放置在windows系统的证书存储区里面，这样既减少证书被盗用的风险，同时通过windows的CSP（Cryptographic Service Provider）能让JS，APP都能读取到相关证书信息。</p>
<h2 id="流程">流程</h2>
<p>当用户登录系统的时候，需要使用该用户对应的私钥进行签名，如果该用户现阶段还没有私钥，则会引导用户跳转到证书申请页面进行申请。申请成功之后，系统自动为用户安装证书，然后用户就能够使用该证书与服务器进行交互了。</p>
<h3 id="证书生成">证书生成</h3>
<p>我们在服务器端通过openssl创建相关证书，主要有以下几个流程：</p>
<ul>
<li><p>创建私钥</p>
<pre><code>  openssl genrsa -out private.key 1024
</code></pre><p>  我们通过genrsa生成了一个1024位的私钥</p>
</li>
<li><p>生成CA</p>
<pre><code>  openssl req -new -x509 -days 3650 -key private.key -out username.crt -subj &quot;/C=CN/ST=GZ/L=ZH/O=KSS/OU=KSS/CN=username&quot;
</code></pre><p>  这里需要特别注意的是证书的CN信息，我们这里使用username来表示，这样CSP就能通过username，使用subjectName来查找相关证书了。为了保证username的私密性，我们也可以对username进行hmac处理。</p>
</li>
<li><p>提取公钥</p>
<pre><code>  openssl rsa -in private.key -out public.key -outform PEM -pubout
</code></pre><p>  提取对应公钥信息，后续服务器会通过该公钥进行验证与加密。</p>
</li>
<li><p>生成pfx</p>
<pre><code>  openssl pkcs12 -export -inkey private.key -in username.crt -password pass: -out username.pfx
</code></pre><p>  将私钥以及证书信息打包进pfx文件，并将该文件分发给用户。因为我们是通过脚本进行证书生成的处理，所以这里需要设置<strong>‘-password pass:’</strong>，用来保证脚本不会被hang up。</p>
</li>
</ul>
<p>证书生成之后，我们会将证书的相关信息存放到数据库，同时将pfx文件分发给用户。</p>
<h3 id="证书导入">证书导入</h3>
<p>因为用户证书的申请是由我们自己的页面进行控制，所以我们通过JS就能将该证书信息下载下来，同时调用CSP相关接口将证书注册进windows的CA Store里面。</p>
<p>在注册证书的时候，需要注意，有可能存在同名的subjectName证书（这种可能出现在用户更换证书的情况），需要首先将其删除。</p>
<h3 id="证书使用">证书使用</h3>
<p>当用户登录的时候，会做如下处理：</p>
<ul>
<li>通过username找到相应的私钥，进行签名sign</li>
<li>服务器收到登录请求之后，通过username找到对应的公钥，进行验证verify</li>
<li>服务器验证通过，则会使用公钥加密一个key返回给用户</li>
<li>用户通过私钥对key进行解密，解开之后，后续的交互通过该key进行。</li>
</ul>
<p>对于其他关键性操作，也使用私钥进行sign，保证其安全性。对于服务器的验证，加密来说，我们使用pycrypto进行，谁叫我们使用的是python开发。</p>
<h2 id="一些坑">一些坑</h2>
<p>为了实现上述功能，我们栽了很多坑，这里记录一下，也供后续参考。</p>
<ul>
<li>字节序问题，windows csp对于sign使用的是小端序，而openssl等都使用的是大端序。所以我们在处理的时候需要进行字节序转换。</li>
<li>openssl rsautl，dgst。这是最坑爹的了，openssl的rsautl貌似已经被废弃了，所以verify的时候不能使用rsautl，只能用dgst才能保证csp sign的数据服务器能verify。但是对于加解密来说rsautl竟然又可以。神奇！</li>
<li>Base64，JS对于二进制流的处理比较蛋疼，所以我们的接口都是使用base64编码的，但python的base64会有一个<strong>‘\n’</strong>，这个就得我们手动去掉了。</li>
<li>CSPICOM，原以为JS能调用CSPICOM就很方便了，但是CSPICOM在win7已经不支持，所以只能我们自己封装一个ActiveX，来调用CSP对应函数。</li>
</ul>
<h2 id="end">end</h2>
<p>CSP的相关代码在<a href="https://gist.github.com/siddontang/5792247" target="_blank" rel="external">这里</a>。需要注意的是，证书的添加以及删除需要使用管理员权限。另外，不得不吐槽一下WIN32的API，笔者是在没有Visual AssixtX写的代码，太辛苦了！</p>
<p>版权声明：自由转载-非商用-非衍生-保持署名 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="external">Creative Commons BY-NC-ND 3.0</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-06-16T14:16:14.000Z"><a href="/2013/06/16/introduction-mtunnel/">06-16-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/06/16/introduction-mtunnel/">mtunnel - a simple http tunnel</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="介绍">介绍</h1>
<p>mtunnel是一个简易的http隧道工具，使用python实现，基于tornado。</p>
<p>为了解决远端用户服务器的一些问题，我们需要远程连接到用户的服务器上面，但因为企业安全性问题，外部根本不可能访问相关服务器，只能通过用户的本地机器去访问，但是用户本地机器也在内网环境下面，外部不能直接连接。</p>
<p>因为用户的机器在内网环境下面，也不可能通过通常的代理去连接。所以比较好的方式就是通过一台双方都能访问的公网服务器，来交换双方的数据。</p>
<p>mtunnel通过http tunnel的方式来进行数据的交互。它将双方交互的数据封装到http的body里面，通过http协议进行传输。这样有几个好处：</p>
<ul>
<li>不用关心交互的具体协议，mtunnel只是将双方交互的所有信息完全封装到http body里面进行传递。</li>
<li>http一般不会被企业的网络安全规则给屏蔽，内网穿透性更好。</li>
</ul>
<p>假设，企业服务器启动了sshd，而我们这边使用putty。流程如下：</p>
<p><img src="https://raw.github.com/siddontang/blog/master/asserts/mtunnel-flow.png" alt="image"></p>
<ul>
<li>putty直接将数据发送给forward proxy，由forward proxy将数据通过http body发送给server。</li>
<li>server收到数据之后将其放置在一个buffer中。如果reverse proxy这时候已经连接到server，则直接将数据发送给reverse proxy。</li>
<li>reverse proxy定时去server获取数据，如果有则将其发送给sshd。</li>
<li>sshd返回的数据同样流程返回给putty。</li>
</ul>
<h2 id="使用">使用</h2>
<p>mtunnel分为3个部分，与putty交互的forward proxy，与sshd交互的reverse proxy以及负责双方数据中转的server。</p>
<h3 id="start_server">start server</h3>
<pre><code>    python server.py -p 8888
</code></pre><p>假设sever的ip地址为10.20.187.118，监听port为8888。</p>
<h3 id="start_reverse_proxy">start reverse proxy</h3>
<p>因为我们需要通过用户本地机器去访问服务器，所以首先必须用户同意让我们访问，也就是他需要在本地启动reverse proxy。</p>
<pre><code>    python rproxy.py -host 10.20.189.241 -p 22 --server 10.20.187.118:8888
</code></pre><p>host和port连接的是sshd的ip和port，而server则是服务器的地址。<br>reverse proxy如果成功连接上了server，则会获取一个channel id。后续所有的通信都必须通过该channel id进行。</p>
<h3 id="start_forward_proxy">start forward proxy</h3>
<pre><code>    python fproxy.py --server 10.20.187.118:8888 --channel 112122 -p 8889
</code></pre><p>我们在本地启动forward proxy，监听本地8889端口，server为服务器的地址，而channel则是用户启动reverse proxy之后获取的channel id，由用户负责告诉我们。</p>
<h3 id="use">use</h3>
<p>当做了上述操作之后，我们只需要启动putty，连接forward proxy。然后putty就能与远端的sshd交互了。</p>
<h2 id="远程协助？">远程协助？</h2>
<p>为什么不使用QQ远程协助这种类似功能？主要有以下几点原因：</p>
<ul>
<li>QQ远程协助能看到用户本地机器的很多信息，企业用户对于安全性问题比较敏感。</li>
<li>网络问题，现在很多企业的网络环境非常不好，我们就碰到过太多次远程的时候网络坑爹造成完全无法工作的情况。</li>
</ul>
<h2 id="后续方向">后续方向</h2>
<p>现在的版本只是一个最基本的版本，很多问题没有考虑，后续主要考虑以下几个方面：</p>
<ul>
<li>安全性，尤其要保证channel id的安全性。后续考虑使用签名机制等。</li>
<li>网络容错，还没怎么很好的处理网络出问题的情况，譬如网络断开等。</li>
<li>P2P，数据都走server会有延时，稳定等问题，如果能够P2P互通，就很强大了。</li>
</ul>
<p>代码在<a href="http://https://github.com/siddontang/mtunnel" target="_blank" rel="external">这里</a>，该版本只是笔者使用python实现的一个非常基础的版本，很多地方存在不足，后续会慢慢完善。</p>
<p>版权声明：自由转载-非商用-非衍生-保持署名 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="external">Creative Commons BY-NC-ND 3.0</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2013-05-29T13:05:05.000Z"><a href="/2013/05/29/nginx-vhost-deploy/">05-29-2013</a></time>
      
      
  
    <h1 class="title"><a href="/2013/05/29/nginx-vhost-deploy/">nginx虚拟主机解决企业内外网访问</a></h1>
  

    </header>
    <div class="entry">
      
        <p>在企业里面部署服务，需要面临的一个问题就是不同企业复杂的网络环境。通常来说，私有云只需要在企业内部使用，但是也有很多企业需要通过外网能访问。同时，对于不同网络的访问请求，系统也需要进行不同的处理。譬如内网用户请求下载直接可以rewrite到对应的内网下载机上，但外网用户请求下载则可能需要通过代理进行。</p>
<p>因为我们的系统使用nginx作为网络总的入口，所以，自然通过部署nginx来解决内外网的访问问题。对于私有云产品来说，内网的nginx server是很好配置的，难点在于如何配置外网的server，因为外网有很多种网络环境，需要分别考虑。</p>
<h2 id="基础知识">基础知识</h2>
<p>在进行配置之前，首先列举一些nginx的配置需要了解的基本知识。</p>
<p>首先，来看一个最简单的nginx配置</p>
<pre><code>http {
    server {
        listen 192.168.1.10:80;
        server_name www.domain.com;
        location / {
            return 200 &quot;Hello World&quot;;
        }
    }
}
</code></pre><p>在上面这个例子中，nginx启动了一个server，该server监听192.168.1.10的80端口，server_name为 www.domain.com。</p>
<p>ip和port大家很好理解，对于server_name，可以认为就是发送http请求header里面的host。</p>
<p>当外部发送 <a href="http://192.168.1.10:80/hello" target="_blank" rel="external">http://192.168.1.10:80/hello</a> 这个http请求的时候，监听80端口的这个server会处理。</p>
<p>同时，我们也可以通过域名来访问，如<a href="http://www.domain.com/hello，因为www.domain.com跟server_name配置一样，所以nginx也能处理响应。当然，前提是企业必须配置dns将该域名指定到192.168.1.10上面。" target="_blank" rel="external">http://www.domain.com/hello，因为www.domain.com跟server_name配置一样，所以nginx也能处理响应。当然，前提是企业必须配置dns将该域名指定到192.168.1.10上面。</a></p>
<p>对于任何http请求，nginx都是首先获取一个匹配的server，而具体nginx选择哪一个server，则是如下流程：</p>
<ul>
<li>通过listen的ip以及port确定server</li>
<li>如果有多个server，则通过server_name再次确定</li>
<li>如果仍然有多个，则按照配置顺序选择第一个</li>
</ul>
<p>所以通过nginx来响应内外网的请求，也就是配置不同server的过程。</p>
<p>对于外网来说，通常来说有2种情况，具有独立的外网IP以及NAT映射的外网IP，如果提供了外网域名，通过域名解析的IP也仍然是上述两种情况。</p>
<h2 id="独立外网IP">独立外网IP</h2>
<p>假设内网ip为192.168.1.10，实际的外网ip为10.20.189.217。</p>
<h3 id="无域名">无域名</h3>
<p>对于具有独立外网IP的机器来说，nginx很好配置。如下</p>
<pre><code>server {
    listen 192.168.1.10:80;
    server_name 192.168.1.10;
}

server {
    listen 10.20.189.217:80;
    server_name 10.20.189.217;
}
</code></pre><p>可以看到，我们直接可以通过listen监听不同的ip来配置内外网server，</p>
<p>或者我们也可以通过如下方式：</p>
<pre><code>server {
    listen 80;
    server_name 192.168.1.10;
}

server {
    listen 80;
    server_name 10.20.189.217;
}
</code></pre><p>这里，nginx监听同一个端口，通过对应的server_name来进行区分内外网。对于有独立外网IP的情况，建议使用前一种方式，直接listen ip:port。</p>
<h3 id="有域名">有域名</h3>
<p>如果有域名，那么我们可以在server_name中填入相应的域名信息。</p>
<pre><code>server {
    listen 192.168.1.10:80;
    server_name www.domain.com;
}

server {
    listen 10.20.189.217:80;
    server_name www.domain.com;
}
</code></pre><p>可以看到，如果内外网都有相同的域名，那么listen的时候就必须得填入ip信息，如果只监听端口，nginx没法通过server_name区分内外网。</p>
<h2 id="NAT外网IP">NAT外网IP</h2>
<p>如果外网IP为NAT映射的，那么nginx是不能直接listen这个IP的。假设NAT映射端口仍然为80，外网NAT地址为10.20.189.217。</p>
<h3 id="无域名-1">无域名</h3>
<pre><code>server {
    listen 80;
    server_name 192.168.1.10;
}

server {
    listen 80;
    server_name 10.20.189.217;
}
</code></pre><p>可以看到，无域名情况比较简单，我们可以通过server_name来区分内外网。</p>
<h3 id="有不同域名">有不同域名</h3>
<p>如果内外网有不同域名，那么情况也跟无域名一样，通过配置server_name区分。</p>
<pre><code>server {
    listen 80;
    server_name www.domain1.com;
}

server {
    listen 80;
    server_name www.domain2.com;
}
</code></pre><h3 id="有相同域名">有相同域名</h3>
<p>如果内外网有相同域名，那么就不能通过监听同一个端口来区分内外网了。笔者能想到的做法就是nginx监听不同的端口。</p>
<pre><code>server {
    listen 80;
    server_name www.domain1.com;
}

server {
    listen 10080;
    server_name www.domain2.com;
}
</code></pre><p>这里，通过监听10080来响应外网的请求，这样NAT的映射端口就需要改变。</p>
<h2 id="end">end</h2>
<p>可以看到，内外网的配置，其实就是nginx vhost的配置，而关键点就在于listen以及server_name。详细可以参考<a href="http://nginx.org/en/docs/http/request_processing.html" target="_blank" rel="external">How nginx processes a request</a>，<a href="http://nginx.org/en/docs/http/server_names.html" target="_blank" rel="external">Server names</a>。</p>
<p>版权声明：自由转载-非商用-非衍生-保持署名 <a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank" rel="external">Creative Commons BY-NC-ND 3.0</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  

  <nav id="pagination">
  
    <a href="/archives/page/5/" class="alignleft prev">上一页</a>
  
  
    <a href="/archives/page/7/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav>
</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:siddontang.com">
  </form>
</div>

  <div class="widget tag">
  <h3 class="title">Github</h3>
  <ul class="entry">
  <li><a href="https://github.com/siddontang/ledisdb" target="_blank">LedisDB</a><small>Fast NoSQL</small></li>
  <li><a href="https://github.com/siddontang/mixer" target="_blank">Mixer</a><small>MySQL Proxy with Go</small></li>
  <li><a href="https://github.com/siddontang/libtnet" target="_blank">Libtnet</a><small>High Performance EventLoop</small></li>
  <li><a href="https://github.com/siddontang/moonmq" target="_blank">MoonMQ</a><small>Fast Message Queue</small></li>
  <li><a href="https://github.com/siddontang" target="_blank">More...</a></li>
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/c++/">c++</a><small>7</small></li>
  
    <li><a href="/categories/elasticsearch/">elasticsearch</a><small>1</small></li>
  
    <li><a href="/categories/go/">go</a><small>29</small></li>
  
    <li><a href="/categories/leetcode/">leetcode</a><small>1</small></li>
  
    <li><a href="/categories/lua/">lua</a><small>2</small></li>
  
    <li><a href="/categories/mysql/">mysql</a><small>3</small></li>
  
    <li><a href="/categories/nginx/">nginx</a><small>2</small></li>
  
    <li><a href="/categories/program/">program</a><small>14</small></li>
  
    <li><a href="/categories/python/">python</a><small>6</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/tags/algorithm/" style="font-size: 10.00px;">algorithm</a><a href="/tags/c++/" style="font-size: 18.89px;">c++</a><a href="/tags/celery/" style="font-size: 10.00px;">celery</a><a href="/tags/docker/" style="font-size: 10.00px;">docker</a><a href="/tags/go/" style="font-size: 20.00px;">go</a><a href="/tags/gopkg/" style="font-size: 10.00px;">gopkg</a><a href="/tags/goroutine/" style="font-size: 10.00px;">goroutine</a><a href="/tags/json/" style="font-size: 10.00px;">json</a><a href="/tags/ledisdb/" style="font-size: 14.44px;">ledisdb</a><a href="/tags/leetcode/" style="font-size: 10.00px;">leetcode</a><a href="/tags/leveldb/" style="font-size: 10.00px;">leveldb</a><a href="/tags/libtnet/" style="font-size: 15.56px;">libtnet</a><a href="/tags/log/" style="font-size: 10.00px;">log</a><a href="/tags/lua/" style="font-size: 13.33px;">lua</a><a href="/tags/message-queue/" style="font-size: 10.00px;">message queue</a><a href="/tags/mixer/" style="font-size: 12.22px;">mixer</a><a href="/tags/moonmq/" style="font-size: 11.11px;">moonmq</a><a href="/tags/mysql/" style="font-size: 17.78px;">mysql</a><a href="/tags/nginx/" style="font-size: 11.11px;">nginx</a><a href="/tags/nosql/" style="font-size: 14.44px;">nosql</a><a href="/tags/polaris/" style="font-size: 11.11px;">polaris</a><a href="/tags/pprof/" style="font-size: 10.00px;">pprof</a><a href="/tags/proxy/" style="font-size: 10.00px;">proxy</a><a href="/tags/python/" style="font-size: 16.67px;">python</a><a href="/tags/reflect/" style="font-size: 10.00px;">reflect</a><a href="/tags/restful/" style="font-size: 10.00px;">restful</a><a href="/tags/rpc/" style="font-size: 10.00px;">rpc</a><a href="/tags/timer/" style="font-size: 11.11px;">timer</a><a href="/tags/timingwheel/" style="font-size: 10.00px;">timingwheel</a><a href="/tags/tornado/" style="font-size: 12.22px;">tornado</a><a href="/tags/zookeeper/" style="font-size: 10.00px;">zookeeper</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 SiddonTang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'siddontang';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>