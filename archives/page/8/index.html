<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第 8 页 | 归档 | Siddon&#39;s Blog</title>
  <meta name="author" content="SiddonTang">
  
  <meta name="description" content="My thought for program">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Siddon&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Siddon&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27956076-1']);
  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Siddon&#39;s Blog</a></h1>
  <h2><a href="/">My thought for program</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/Presentations">Presentations</a></li>
    
      <li><a href="/About">About</a></li>
    
      <li><a href="/atom.xml">RSS</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
<h2 class="archive-title">归档</h2>


  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2012-09-02T10:00:00.000Z"><a href="/2012/09/02/step-by-step-network/">09-02-2012</a></time>
      
      
  
    <h1 class="title"><a href="/2012/09/02/step-by-step-network/">深入浅出网络模型</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="前言">前言</h1>
<p>对于高性能web服务器来说，一个好的网络模型是必不可少的，这样能让程序员专注于上层业务逻辑的开发，而不需要过多的关注底层网络的交互。虽然网上现在有很多介绍高性能网络架构的文章，但是这里我还是想自己结合多年的开发经验总结一下，也当算是自己知识的沉淀。</p>
<p>测试环境</p>
<ul>
<li>os: mac os 10.7.4</li>
<li>cpu: intel core i5 1.7 GHz</li>
<li>mem: 4G 1600 MHz DDR3</li>
</ul>
<p>开发工具</p>
<ul>
<li>python: 2.7</li>
</ul>
<p>测试工具</p>
<ul>
<li>tool: http-load</li>
</ul>
<p>这里，需要说明几个问题</p>
<ul>
<li>只考虑单机，不提整体分布式。</li>
<li>os的选择，unix/linux都可以，而windows则没有考虑，虽然它有很强的iocp机制用来高效的处理网络。</li>
<li>语言的选择，对于io密集型的程序，语言的差别是很小的，c/c++在碰到io操作的时候性能不见得比python高多少，而python的开发非常的快速，所以我选择了python。但如果是cpu密集型程序，c/c++那真还是王道了。</li>
<li>测试工具的选择，虽然有很多测试web服务器性能的工具，之所以选择http-load，主要还是在于它足够简单，而且我只需要进行大概比较，来说明网络模型的性能，所以当然是越简单越好。</li>
</ul>
<h1 id="一个简单的web_server">一个简单的web server</h1>
<p>首先我们来看一个简单的web server例子</p>
<pre><code>import socket

HOST = &#39;127.0.0.1&#39;                 
PORT = 8888              

msg = &#39;200 OK HTTP/1.1\r\n\r\nHello World&#39;

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind((HOST, PORT))
s.listen(1)

def hello(conn):
    conn.recv(1024)

    conn.sendall(msg)
    conn.shutdown(socket.SHUT_RDWR)
    conn.close()

while 1:
    conn, addr = s.accept()
    hello(conn)
</code></pre><p>上面是一个简单的web server，它接受client的连接，读取client的数据，并且发回一个hello world，就这么简单。不过它的缺点也很明显，只能处理单个连接，不能同时处理多个连接。也就是说，这个server处理不了并发。</p>
<h1 id="blocking_io_+_multi_process">blocking io + multi process</h1>
<p>为了解决上面的问题，我们引入process或者thread，也就是说，当server accept一个client请求之后，会将其扔到一个新的进程或者线程中去，而主循环继续处理下一个连接请求，这样就能保证并发。</p>
<p>在早期的unix系统中，推荐使用fork模型，也就是将socket扔入一个新创建的进程中。因为在unix下面，fork很迅速，并且开销很小。</p>
<pre><code>while 1:
    conn, addr = s.accept()

    if os.fork() &gt; 0:
        conn.close()

        continue

    hello(conn)

    os._exit(0)
</code></pre><p>当accept成功之后，server使用fork创建一个子进程，然后父进程继续监听网络连接。而后续所有与client的交互都是在子进程里面进行，这样就有了并发。</p>
<p>这里需要注意一点，mac下面系统默认max user processes是一个很小的数，我的为709，如果不能调高，很容易就会因为fork太多导致Resource temporarily unavailable，但是mac下面坑爹的是ulimit -u竟然无效，google了一下找到一些<a href="http://blog.ghostinthemachines.com/2010/01/19/mac-os-x-fork-resource-temporarily-unavailable/" target="_blank" rel="external">解决方案</a>。</p>
<p>补充一点，上面这个程序即使把process的数量设置的在高，也会造成process资源的耗尽，原因在于僵尸进程，具体可以参考<a href="http://blog.csdn.net/yygydjkthh/article/details/7342160" target="_blank" rel="external">两次fork</a>，以及<a href="http://mildopinions.wordpress.com/2008/05/31/python-and-parallel-programming/" target="_blank" rel="external">python-and-parallel-programming</a></p>
<p>对于fork，为了防止僵尸进程问题，开始我使用注册singal的方式处理，如下</p>
<pre><code>def handleSIGCHLD(num, stackframe):
    if num == signal.SIGCHLD:
    try:
        (pid, status) = os.waitpid(-1, os.WNOHANG)
    except:
        pass


signal.signal(signal.SIGCHLD, handleSIGCHLD)
</code></pre><p>但是却发现在socket accept的时候，老是出现</p>
<pre><code>socket.error: [Errno 4] Interrupted system call
</code></pre><p>这样的错误，原因在于socket的系统调用可能会被signal打断，不过对于信号这个东西，本来我也不怎么感冒，就不想深究了。所以有了后一种简单的做法，就是在accept之前waitpid一下，这样就能回收一些僵尸进程，只不过可能还是有一些进程无法回收，不过觉得也能接受了。对于二次fork解决方案，感觉fork的开销还是有的，这里就不怎么想用了。</p>
<h1 id="blocking_io_+_multi_thread">blocking io + multi thread</h1>
<p>对于thread，代码差别不大，只需要将首发数据的功能移到thread里面</p>
<pre><code>def callback(conn):
    hello(conn)

while 1:
    conn, addr = s.accept()

    th = threading.Thread(target=callback, kwargs = {&#39;conn&#39;:conn})
    th.start()
</code></pre><h1 id="multi_process_vs_multi_thread">multi process vs multi thread</h1>
<p>网上有太多分析多进程和多线程的文章，譬如这篇<a href="http://www.geekride.com/fork-forking-vs-threading-thread-linux-kernel/" target="_blank" rel="external">Forking vs Threading</a>，而我本机的测试结果如下：</p>
<pre><code>siddontang:~/repository/perfsvr $ http_load -p 10 -fetches 5000 url.list 
5000 fetches, 10 max parallel, 55000 bytes, in 1.55861 seconds
11 mean bytes/connection
3207.98 fetches/sec, 35287.8 bytes/sec
msecs/connect: 0.265093 mean, 20.846 max, 0.197 min
msecs/first-response: 2.78085 mean, 23.332 max, 0.584 min
HTTP response codes:

siddontang:~/repository/perfsvr $ http_load -p 10 -fetches 5000 url.list 
5000 fetches, 10 max parallel, 55000 bytes, in 2.73079 seconds
11 mean bytes/connection
1830.97 fetches/sec, 20140.7 bytes/sec
msecs/connect: 0.244044 mean, 10.649 max, 0.063 min
msecs/first-response: 5.12083 mean, 12.943 max, 0.436 min
HTTP response codes:
</code></pre><p>第一个测试结果是thread的，第二个为process，可以看到，thread的性能要好于process，不过也不能因此下结论multi thread模型就更好，因为我这个只是简单的测试。</p>
<p>之所以要写multi process/thread主要是因为，在上面这两种模型下面，如果并发量大的时候，都会遇到一个比较严重的问题，就是系统切换开销以及内存压力。这里有一个<a href="http://bulk.fefe.de/scalability/" target="_blank" rel="external">benchmark</a>。</p>
<h1 id="non_blocking_socket">non blocking socket</h1>
<p>上面说的网络模型都是基于blocking socket，所谓blocking socket就是当socket在send或者recv的时候，进程/线程会一直block直到io完成。我们之所以会对于每一个连接启用一个进程/线程，就是不能因为io的block导致整个系统的block。而non blocking socket则没有这种问题，当一个socket是non blocking的时候，它在调用send，recv等时候可能会立即返回而不作任何事情，而后续的事情我们通过其他机制获得并处理。这样就不会因为io的block造成整个程序的block。</p>
<h1 id="select/epoll/kqueue">select/epoll/kqueue</h1>
<p>对于non blocking socket，我们可以使用select等进行监听，当这个socket可读，可写等状态的时候，select会触发相应的回调进行处理。同时，select可以监听多个non blocking socket，这样就达到了多路复用io的效果。而对于epoll，kqueue，大概原理一样，只是在实现上面不一样罢了。</p>
<p>这里，我决定开始直接使用tornado的源码，这里不得不佩服tornado的强悍，一个ioloop就封装好了所有的东西，并且可以随时切换。因为在mac，所以只能使用select和kqueue。</p>
<h2 id="select">select</h2>
<p>在tornado里面使用select很简单，需要注意两点：</p>
<ul>
<li>通过IOLoop传入特定的poll机制。</li>
<li>application的listen里面会使用IOLoop的单件，所以生成的ioloop需要install一下  </li>
</ul>
<p>代码如下：</p>
<pre><code>class MainHandler(tornado.web.RequestHandler):
    def get(self):
        self.write(&quot;Hello, world&quot;)

application = tornado.web.Application([
    (r&quot;/&quot;, MainHandler),
])

loop = tornado.ioloop.IOLoop(tornado.ioloop._Select())
loop.install()
application.listen(8888)
loop.start()
</code></pre><p>使用http_load的测试结果，可以看到，在同时100并发的情况下面，性能很不错。而先前multi process/thread模型在我的机器上面当并发量为100的时候已经有很多请求处理不过来直接报错了。</p>
<pre><code>siddontang:~/repository/perfsvr $ http_load -p 100 -fetches 5000 url.list 
5000 fetches, 100 max parallel, 60000 bytes, in 2.05569 seconds
12 mean bytes/connection
2432.28 fetches/sec, 29187.3 bytes/sec
msecs/connect: 0.192841 mean, 3.623 max, 0.082 min
msecs/first-response: 40.5787 mean, 105.812 max, 15.746 min
HTTP response codes:
code 200 -- 5000
</code></pre><p>再来说说select的使用方式。select会关心3个队列，read，write和error，对于一个socket而言，它如果对某一种事件感兴趣，就加入到相应的队列里面去。譬如一个socket这时候只关心是否能read，那它就加入read队列。而select则在每次运行的时候，依次去遍历这些队列，看里面哪些socket准备就绪可以操作了，如果有将他加入一个可处理的列表里面去。tornado下面select使用代码如下：</p>
<pre><code>def poll(self, timeout):
    readable, writeable, errors = select.select(
        self.read_fds, self.write_fds, self.error_fds, timeout)
    events = {}
    for fd in readable:
        events[fd] = events.get(fd, 0) | IOLoop.READ
    for fd in writeable:
        events[fd] = events.get(fd, 0) | IOLoop.WRITE
    for fd in errors:
        events[fd] = events.get(fd, 0) | IOLoop.ERROR
    return events.items()
</code></pre><h2 id="kqueue">kqueue</h2>
<p>让tornado支持kqueue模式很简单，mac下面就自动就是的，不过为了与select对比，我们使用如下方式</p>
<pre><code>loop = tornado.ioloop.IOLoop(tornado.ioloop._Kqueue())
</code></pre><p>测试结果如下</p>
<pre><code>siddontang:~/repository/perfsvr $ http_load -p 100 -fetches 5000 url.list 
5000 fetches, 100 max parallel, 60000 bytes, in 2.44096 seconds
12 mean bytes/connection
2048.38 fetches/sec, 24580.5 bytes/sec
msecs/connect: 7.95017 mean, 32.623 max, 0.49 min
msecs/first-response: 40.0568 mean, 73.247 max, 14.235 min
HTTP response codes:
code 200 -- 5000
</code></pre><p>可以看到，kqueue的结果也是挺不错的，能够支持高并发量的处理，但是与select对比发现，select的性能竟然比kqueue要高，这个在某些时候是的，我后续在说明。</p>
<p>这里先说明一下kqueue的工作方式，相比于select，我感觉kqueue强大了很多，对于kqueue的设计，具体可以参考这篇<a href="https://docs.google.com/viewer?url=http%3A%2F%2Fpeople.freebsd.org%2F~jlemon%2Fpapers%2Fkqueue.pdf" target="_blank" rel="external">paper</a>。kqueue不光可以处理socket的事件，同时还能处理异步io，信号，文件变化等，感觉就是事件监听一锅端，不过接口还是挺好理解的。</p>
<p>kqueue有两个部分，kqueue和kevent。kqueue主要是用来描述event的队列，它通过control这个函数来获取当前有变化的event。而kevent则是对应的相应事件。</p>
<p>kevent的<a href="http://www.freebsd.org/cgi/man.cgi?query=kqueue&amp;sektion=2" target="_blank" rel="external">详细说明</a>，如果只是监听socket的，我们需要关注如下几个东西:</p>
<ul>
<li>ident kevent的一个唯一标识符，一般我们就用需要监控的文件句柄表示</li>
<li>filter 过滤器，一般关注KQ_FILTER_READ和KQ_FILTER_WRITE，即可读可写。</li>
<li>flag filter之后需要关注的action，一般为KQ_EV_ADD（添加），KQ_EV_DELETE（删除），KQ_EV_EOF（EOF）和KQ_EV_ERROR（出错）</li>
</ul>
<p>kqueue的poll代码如下：</p>
<pre><code>def poll(self, timeout):
    kevents = self._kqueue.control(None, 1000, timeout)
    events = {}
    for kevent in kevents:
        fd = kevent.ident
        if kevent.filter == select.KQ_FILTER_READ:
            events[fd] = events.get(fd, 0) | IOLoop.READ
        if kevent.filter == select.KQ_FILTER_WRITE:
            if kevent.flags &amp; select.KQ_EV_EOF:
                events[fd] = IOLoop.ERROR
            else:
                events[fd] = events.get(fd, 0) | IOLoop.WRITE
        if kevent.flags &amp; select.KQ_EV_ERROR:
            events[fd] = events.get(fd, 0) | IOLoop.ERROR
    return events.items()
</code></pre><h2 id="epoll">epoll</h2>
<p>对于epoll，因为我本机没有环境无法测试，加之网上介绍epoll的资料太多了，就不多做介绍了。这里需要关注它的两种模式，edge trigger和level trigger，通俗点说，就是如下：</p>
<ul>
<li>edge trigger：有了消息，通知你一次，你不处理完成，拉倒，再也不通知你了，直到下次来消息。</li>
<li>level trigger：有了消息，通知你，你不处理，一直通知你，直到你处理完。</li>
</ul>
<p>kqueue也有这两种模式，通过KQ_EV_CLEAR来设置，这里就不深入讨论了。</p>
<h2 id="why_kqueue_and_epoll_are_better">why kqueue and epoll are better</h2>
<p>说完了这三种实现，现在来探讨一个问题，为什么kqueue和epoll比select好。从机制上面说，kqueue和epoll只关注有事件发生的socket，而select则需要将所有的注册socket遍历一遍，光从每次遍历的socket对象来说，select就要比kqueue和epoll多查看几个。</p>
<p>所以，在连接数较多并且很多socket不是特别活跃的时候，select的性能是有问题的，但是如果在连接数较少并且socket活跃的时候，select的性能很不错，并且不必kqueue和epoll差。</p>
<p>这是从对socket遍历机制上面说，为什么kqueue和epoll性能高。但如果在深入一点呢？</p>
<h3 id="epoll/kqueue实现浅析">epoll/kqueue实现浅析</h3>
<p>我们来想想，如果要实现一个类似epoll的功能怎么做呢？</p>
<ul>
<li>需要一个数据结果来保存整个注册的socket，而且要非常快速的进行socket的插入，删除操作，这个使用红黑树是一个很不错的想法，性能为O(lgn)。</li>
<li>当一个socket有事件发生的时候，系统中断会通过描述符找到对应的socket，然后我们将其加入一个队列里面去</li>
<li>外部拿到这个可处理队列就可以进行操作，如果设置为level。 trigger，那么处理一轮过后，检查对应的socket是否还有东西需要处理，有的话则继续加入队列，如果为edge trigger则不管了。</li>
</ul>
<p>照理说，kqueue应该也实现同样的功能，但从这篇<a href="https://docs.google.com/viewer?url=http%3A%2F%2Fpeople.freebsd.org%2F~jlemon%2Fpapers%2Fkqueue.pdf" target="_blank" rel="external">paper</a>可以看出，对于socket的保存，kqueue直接使用了一个array，就跟系统的open file table一样，为什么这么做呢？因为对于进程来说，它都有一个max file的最大值，譬如1024，所以分配文件的描述符最大是不会超过1024的，而且类unix系统上面分配的文件描述符都默认取得是最小的一个可用的，基于这些，我们就可以使用一个array来进行索引。对于这点<a href="http://developer.cybozu.co.jp/kazuho/2009/08/picoev-a-tiny-e.html" target="_blank" rel="external">picoev</a>这个网络框架库可算是用到了极致。后续有机会在介绍。</p>
<h1 id="多路复用socket_+_thread_pool_for_logic">多路复用socket + thread pool for logic</h1>
<p>上面介绍了多路复用IO，那么当然我们就要考虑使用这个技术来搭建服务器了。以kqueue为例，我们得面对一个问题，虽然系统处理网络的能力提升了，但是如果收到数据之后我们需要进行一个费时的逻辑操作，仍然会导致整体的性能下降。所以我们就需要一套机制来分解网络和逻辑。</p>
<p>一个比较好的做法就是网络使用一个线程，而逻辑处理使用另一个线程，两个线程之间通过消息队列进行交互。这样当网络线程收到消息处理之后，它只需要将socket的fd以及对应的信息放进消息队列里面，就可以继续处理下一个网络请求了。而逻辑线程则从队列里面取出消息，处理，完成之后将fd以及对应的返回消息放到一个队列里面，让网络线程取出处理就可以了。因为逻辑处理算是一个比较消耗的操作，一般会启用多个逻辑线程，也就是用thread pool进行管理。</p>
<p>这个模型是不错的，那么如果网络线程压力顶不住了，怎么办呢？一般的做法也是开启多个线程用于处理网络，每个线程listen同一个端口，这样就可以进行负载均衡，而每个网络线程仍然对应一批逻辑线程。</p>
<p>网络线程与逻辑线程之间的交互通过消息队列是一个比较好的方式，但因为涉及到多线程，多消息队列的操作仍然会涉及到锁的操作，所以有时候还会其它的一些方式。</p>
<h2 id="多队列缓冲机制">多队列缓冲机制</h2>
<p>这个机制是我以前做游戏服务器的时候跟同事弄出来的一个东西，不知道业界有没有同样的做法的。流程如下:</p>
<ul>
<li>网络线程自己维护一个队列，新收到了消息就加入队列，这个是没有任何锁开销的</li>
<li>到一定阶段，譬如网络线程循环转了几圈，或者消息队列达到一定数量，则将该消息队列splice到一个中间队列，这个是需要锁保护的，而且这个只会涉及到指针的交互，所以会很快速</li>
<li>逻辑线程将中间队列splice到自己的消息队列种，同时将中间队列置空，这样逻辑线程就能拿到整个消息队列了，这个也是需要锁保护的，同理，只会涉及到指针的操作，会很快速</li>
<li>逻辑线程依次取出消息处理，这个也就没有任何锁开销了</li>
</ul>
<p>可以看出，这套机制是以降低消息的及时性为代价的，不过鉴于消息本来就是异步的，线程级别之间稍微的延后跟网络比起来我觉得问题还不大。</p>
<h2 id="无锁的ring_buffer">无锁的ring buffer</h2>
<p>无锁的ring buffer这种结构是我在另一家公司接触到的技术，原理如下：</p>
<ul>
<li>估算分配一块内存用作ring buffer，这块区域是不会在变化的了</li>
<li>线程A只会往ring buffer里面写数据，使用tail来表明下一个可写入位置，线程B只会从里面读数据，使用head来表明下一个可读取的位置</li>
<li>当head = tail的时候，认为buffer为空，没有数据</li>
<li>当tail + 1 = head的时候，认为队列满了，无法在写入数据，为什么要留出一个元素空间呢，因为如果不留出，那么buffer满也是tail = head，而这个就无法跟buffer为空区分了。</li>
<li>线程A写入数据的时候，首先判断buffer是否有足够的空间写入，如果能写入，就写入数据，同时更新tail的位置</li>
<li>线程B读取数据的时候，首先判断buffer是否有足够的数据可读，如果能读取，则读取数据，同时更新head的位置</li>
</ul>
<p>这里，可能会有人疑惑，为什么这个是线程安全的？</p>
<ul>
<li>首先，我们知道，对于head和tail数值的读取是线程安全的，为什么这么说，在c种，head和tail就是指针，而对于指针的读取，是一个原子操作，这个是线程安全的。</li>
<li>以写入为例，线程A首先会读取head和tail的当前值，后续即使线程B修改了head的值，也不会影响这次的写入操作。因为B修改了head，表明A可以写入更多数据，但A获取到的head仍然是先前的值，所以能写入的数据就会按照先前的head计算。当A写入数据之后，更新tail的值。读取跟写入的原理一样。</li>
</ul>
<p>而这个在linux内核里面是有实现的，可以看<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-lockfree/index.html" target="_blank" rel="external">这里</a>.</p>
<h1 id="总结">总结</h1>
<p>写了这么多字，感觉可以手工了。这只是我个人经验，可能还会有更好的做法。对于高性能服务器而言，网络只是需要考虑的一个方面，还会有很多问题需要考虑。其实更需要关注的是整体架构以及整体的性能调优。</p>
<p>另外，感觉还缺少了很多图片，总觉得纯靠文字很多问题还是说的不够深入，后续还是把图片给补上。另外在搭配一个ppt，当然准备使用express.js做，感觉就完美了。</p>
<p>不过，总觉得还是有很多东西可以说的，对于网络这块，我还会继续深入研究，譬如底层的tcp/ip协议，p2p等。希望到时候能有更好的总结。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2012-08-20T10:00:00.000Z"><a href="/2012/08/20/safe-server-interaction/">08-20-2012</a></time>
      
      
  
    <h1 class="title"><a href="/2012/08/20/safe-server-interaction/">思考的一套安全的服务交互模型</a></h1>
  

    </header>
    <div class="entry">
      
        <p>在服务器端，一般采用多服的方案来进行架构，也就是一个服务器只提供特定的服务。客户端要完成一个功能，可能需要访问不同服务器，而这时候就会有很多问题，包括服务器之间如何交互，客户端与服务器如何交互，安全问题等。</p>
<h1 id="安全的登陆">安全的登陆</h1>
<p>对于用户来说，他要使用服务，首先需要做的事情就是登陆，对于登陆来说，我们可以通过oauth，openid等方案，将整个登陆验证交给其他服务提供商（譬如google）来进行。但是，在某些时候，我们仍然需要通过username + password的方式来登陆。这里就有一个问题，如何保证账号密码的安全性？</p>
<p>我觉得，通常一般有如下几种做法：</p>
<ul>
<li><p>使用username + md5(password)的方式，这样的方式虽然不会导致用户的密码明文泄漏，但是如果中途通信被窃听，窃听者直接使用username和密文密码就可以直接登陆了。</p>
</li>
<li><p>在登陆之前，服务器首先下发一个随机的aes key，用户使用key将username + md5(password)进行加密。<br>  对于key服务器应该有一个时间限制，即在一段时间之后，该key就失效。这样即使通信被窃听了，破解获取username + md5（password）的时间较长，同时即使使用相同的信息登陆，因为key的时效性，也可能会因为key的失效失败。</p>
<p>  这种方式比较容易实现，但是如果在服务器下发aes key下发的时候就被窃取到了，那么用户的username和md5(password)信息就很容易被窃取到了。</p>
</li>
<li><p>使用https，貌似这是最安全的一种方式，但是https的证书是要钱的，虽然有免费的，但是限制颇多。<br>  另外https也可能出现证书欺骗，所以在某种程度上面来说也是不安全。不过鉴于很多网站都使用https处理登陆，所以现阶段来说还是很安全的。</p>
</li>
</ul>
<p>除了上面的几种方法之外，还有很多其他的处理方式，这里不在详细表述，但是对于我来说，现阶段因为关注点在web上面，所以使用https算是一个很好的方案，所以后续所有客户端与服务器的交互，都准备采用https协议。</p>
<h1 id="高效的交互">高效的交互</h1>
<p>当用户登陆之后，我们会给用户生成一个对应的stub（存根），后续用户只要拿着这个存根就能继续访问login server了。这里引入了stub概念，因为对于client来说，它不可能每次与server交互都使用username + password等方式，所以通过引入stub，来维持client与server的会话状态。</p>
<p>当然，stub不可能一直有效，如果一直有效，那么如果其他用户拿到了这个stub，就可以欺骗server访问服务器了。所以stub一般都有一个时效性的。</p>
<p>通常的做法，是server会在一个地方保存stub的信息，譬如在memcache里面，然后该stub会对应一些信息（譬如stub创建时间，过期时间），当每次交互的时候，server在cache里面查询到这个stub对应的信息，如果查询不到该stub，那我们就认为这是一次非法的会话，需要用户重新登陆。而如果查询到了相关信息，则判断stub是否过期，如果过期，仍然需要用户重新登录再次去申请新的stub。</p>
<p>但是这种方式，有几个问题：</p>
<ul>
<li>stub存放到一个cache里面，所有与server的交互都会访问该cache，即使memcache很快，但是可能部署在不同的物理机器上面，网络还是有开销的。</li>
<li>单点问题，如果cache挂掉了，那么在一定时间里面，所有的访问都是非法的。即使cache能很快恢复，但是会导致所有的stub都必须重新申请了。</li>
</ul>
<p>鉴于上述情况，我考虑使用另一种方式。</p>
<ul>
<li>提供一个key gen服务，该服务每隔一段时间生成一个aes key，推送到server上面。每一个server保存当前aes key以及上一次推送过来的key</li>
<li>生成stub的时候，使用当前的key加密一段数据（包括创建时间，过期时间等），将加密过的这段数据作为stub</li>
<li>client通过stub访问的时候，server使用当前的key或者上一次key进行解密，如果解密成功，那么就认为是合法的stub</li>
<li>stub通过key解密出来的数据，判断是否过期，如果过期或者解密失败，则需要client重新在申请新的stub</li>
</ul>
<p>这套机制有点在于对于stub的校验与存储不需要一个中心cache来处理，即使key gen服务当掉了，重启生成一个新的key的时候，也能够保证上一次的key有效，尽量减少重新申请stub的client数量。</p>
<h1 id="信任链机制">信任链机制</h1>
<p>前面说了，对于登陆流程来说，采用的是https的方式进行，但是还存在一个问题，即对于分布式服务器来说，每一个服务器怎么认为客户端是可信任的。</p>
<p>对于login server来说，可以认为访问它的client是可信任的，因为client能提供正确的登陆信息（譬如username + password或者oauth的token），但是对于其他server，是不知道这些信息的。所以我们需要一套机制来来让server知道client是可信任的。</p>
<p>这里，我准备采用一种信任链的方式，即如果client可以通过login server向其他server申请一个stub，然后client就可以通过这个stub来访问该服务。</p>
<p>对于信任链我们可以这么理解，如果a信任b，b信任c，那么a也就信任c。那么对于我们整个信任体系，可以这样，假设server1信任client，client需要访问server2，流程可以这样：</p>
<ul>
<li>server1向server2申请一个stub</li>
<li>server2给server1返回一个stub</li>
<li>server1向client返回stub</li>
<li>client通过stub访问server2</li>
</ul>
<p>这里同时需要处理一个问题，client可以通过一些机制让server可信，那么server之间如何互信，即server2为什么允许server1去申请stub。</p>
<p>其实，对于server来说，它既是一个server（为client提供服务），也同时算是一个client（需要访问其他服务）。所以在某些方面，server与server的交互可以当成client与server的交互一样处理。只是我们不是通过username + password形式。</p>
<p>一般server之间互相信任，是比较容易处理的。通常有几种做法：</p>
<ul>
<li>iptable 因为server都是我们内部自己部署配置，所以iptable可以很好的解决server信任问题</li>
<li>公私钥 server1有一个priv key，server2有一个对应的public key，server1与server2第一次交互的时候通过公私钥验证。验证通过之后，server2会生成一个stub，后续server1会通过这个stub访问server2，直到stub失效。<br>  这里我们需要注意，这里的公私钥跟前面提到的https是不一样的，前面的https是保证整个通信信道的安全，而这里是为了验证是否可信。</li>
</ul>
<h1 id="权限机制">权限机制</h1>
<p>对于server来说，它对外提供相应的服务，而这些服务是通过api来暴露的。对于client来说，即使它是可信的，但是对于某些api接口，只能由特定的用户去访问，所以我们还需要实现一套api的权限认证机制。</p>
<p>一般的做法，对于一个用户，有相应的角色，譬如普通用户，管理员等。然后会有一个权限表，存储的是相应角色对应的可访问api。当用户访问server调用相应api的时候，会首先看该角色是否有权限，如果有权限，则允许调用。</p>
<p>当用户首先登陆的时候，会在login server里面获取到其对应的角色。那么我们还需要面对一个问题，权限表怎么存储？对于一个server来说，某一个权限对应相应的api这个是预先可以定义的，所以我们可以在server启动的时候就放置在内存里面，这样当用户访问服务的时候就可以直接通过内存里面的权限表知道是否可访问。那么现在又有一个问题，用户每次访问都需要带上role这一个参数？从前面可知，client通过stub与server进行通信，所以我们可以在生成stub的时候直接将用户的role放置在stub里，这样server解开这个stub之后就可以得到相应的role了。</p>
<h1 id="总结">总结</h1>
<p>上面介绍的就是设想的一套安全高效的分布式服务器架构。当然对于分布式服务来说，还有很多问题没有考虑，譬如负载均衡，数据库等问题，后续我会不断探索思考，归纳总结。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  

  <nav id="pagination">
  
    <a href="/archives/page/7/" class="alignleft prev">上一页</a>
  
  
  <div class="clearfix"></div>
</nav>
</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:siddontang.com">
  </form>
</div>

  <div class="widget tag">
  <h3 class="title">Github</h3>
  <ul class="entry">
  <li><a href="https://github.com/siddontang/ledisdb" target="_blank">LedisDB</a><small>Fast NoSQL</small></li>
  <li><a href="https://github.com/siddontang/mixer" target="_blank">Mixer</a><small>MySQL Proxy with Go</small></li>
  <li><a href="https://github.com/siddontang/libtnet" target="_blank">Libtnet</a><small>High Performance EventLoop</small></li>
  <li><a href="https://github.com/siddontang/moonmq" target="_blank">MoonMQ</a><small>Fast Message Queue</small></li>
  <li><a href="https://github.com/siddontang" target="_blank">More...</a></li>
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/c++/">c++</a><small>7</small></li>
  
    <li><a href="/categories/elasticsearch/">elasticsearch</a><small>1</small></li>
  
    <li><a href="/categories/go/">go</a><small>30</small></li>
  
    <li><a href="/categories/leetcode/">leetcode</a><small>1</small></li>
  
    <li><a href="/categories/lua/">lua</a><small>2</small></li>
  
    <li><a href="/categories/mysql/">mysql</a><small>4</small></li>
  
    <li><a href="/categories/nginx/">nginx</a><small>2</small></li>
  
    <li><a href="/categories/program/">program</a><small>15</small></li>
  
    <li><a href="/categories/python/">python</a><small>6</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/tags/algorithm/" style="font-size: 10.00px;">algorithm</a><a href="/tags/c++/" style="font-size: 18.89px;">c++</a><a href="/tags/celery/" style="font-size: 10.00px;">celery</a><a href="/tags/docker/" style="font-size: 10.00px;">docker</a><a href="/tags/go/" style="font-size: 20.00px;">go</a><a href="/tags/gopkg/" style="font-size: 10.00px;">gopkg</a><a href="/tags/goroutine/" style="font-size: 10.00px;">goroutine</a><a href="/tags/json/" style="font-size: 10.00px;">json</a><a href="/tags/ledisdb/" style="font-size: 15.56px;">ledisdb</a><a href="/tags/leetcode/" style="font-size: 10.00px;">leetcode</a><a href="/tags/leveldb/" style="font-size: 10.00px;">leveldb</a><a href="/tags/libtnet/" style="font-size: 15.56px;">libtnet</a><a href="/tags/log/" style="font-size: 10.00px;">log</a><a href="/tags/lua/" style="font-size: 13.33px;">lua</a><a href="/tags/message-queue/" style="font-size: 10.00px;">message queue</a><a href="/tags/mixer/" style="font-size: 12.22px;">mixer</a><a href="/tags/moonmq/" style="font-size: 11.11px;">moonmq</a><a href="/tags/mysql/" style="font-size: 17.78px;">mysql</a><a href="/tags/nginx/" style="font-size: 11.11px;">nginx</a><a href="/tags/nosql/" style="font-size: 14.44px;">nosql</a><a href="/tags/polaris/" style="font-size: 11.11px;">polaris</a><a href="/tags/pprof/" style="font-size: 10.00px;">pprof</a><a href="/tags/proxy/" style="font-size: 10.00px;">proxy</a><a href="/tags/python/" style="font-size: 16.67px;">python</a><a href="/tags/reflect/" style="font-size: 10.00px;">reflect</a><a href="/tags/restful/" style="font-size: 10.00px;">restful</a><a href="/tags/rpc/" style="font-size: 10.00px;">rpc</a><a href="/tags/timer/" style="font-size: 11.11px;">timer</a><a href="/tags/timingwheel/" style="font-size: 10.00px;">timingwheel</a><a href="/tags/tornado/" style="font-size: 12.22px;">tornado</a><a href="/tags/xcodis/" style="font-size: 10.00px;">xcodis</a><a href="/tags/zookeeper/" style="font-size: 10.00px;">zookeeper</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 SiddonTang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'siddontang';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>